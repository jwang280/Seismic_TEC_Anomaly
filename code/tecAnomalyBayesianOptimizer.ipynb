{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 2571,
     "status": "ok",
     "timestamp": 1611704612887,
     "user": {
      "displayName": "Jay Wang",
      "photoUrl": "",
      "userId": "08806282010227278078"
     },
     "user_tz": -780
    },
    "id": "GoKRT1nAkT4X"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "from __future__ import print_function\n",
    "from datetime import datetime\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.utils import shuffle\n",
    "#from keras.models import Sequential, Model\n",
    "#from keras.layers import Dense, Dropout, BatchNormalization, Activation, Conv2D, MaxPooling2D, Flatten, ConvLSTM2D, MaxPooling3D, Reshape, LSTM\n",
    "from keras.optimizers import *\n",
    "#from keras.callbacks import EarlyStopping\n",
    "#from keras.utils.np_utils import to_categorical\n",
    "#from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold\n",
    "import keras.backend as K\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Activation, MaxPooling2D, Flatten, MaxPooling3D, Reshape, LSTM\n",
    "from tensorflow.keras.layers import ConvLSTM2D # problems with _long_ sequences: https://machinelearningmastery.com/prepare-univariate-time-series-data-long-short-term-memory-networks/\n",
    "#from tensorflow.keras.utils import plot_model\n",
    "# from tensorflow.keras.layers import Conv2D # different location in Keras\n",
    "from tensorflow.keras.callbacks import History\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "#from bayes_opt import BayesianOptimization\n",
    "from bayesian_optimization import BayesianOptimization\n",
    "from sklearn.model_selection import KFold\n",
    "from timeit import timeit\n",
    "from tensorflow.keras.utils import Sequence, plot_model\n",
    "from tensorflow.keras.backend import sqrt, square, mean\n",
    "import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 874,
     "status": "ok",
     "timestamp": 1611704616587,
     "user": {
      "displayName": "Jay Wang",
      "photoUrl": "",
      "userId": "08806282010227278078"
     },
     "user_tz": -780
    },
    "id": "cenQn41fUBw3"
   },
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(history):\n",
    "    historydf = pd.DataFrame(history.history, index=history.epoch)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    historydf.plot(ylim=(0, max(1, historydf.values.max())))\n",
    "    loss = history.history['loss'][-1]\n",
    "    acc = history.history['accuracy'][-1]\n",
    "    plt.title('Loss: %.3f, Accuracy: %.3f' % (loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 853,
     "status": "ok",
     "timestamp": 1611704622016,
     "user": {
      "displayName": "Jay Wang",
      "photoUrl": "",
      "userId": "08806282010227278078"
     },
     "user_tz": -780
    },
    "id": "VPQq6mxrUwUA"
   },
   "outputs": [],
   "source": [
    "trainingDataRoot = '../TrainingData'\n",
    "#trainingFileList = [f for f in os.listdir(trainingDataRoot) if f.endswith('.npy') and os.path.isfile(os.path.join(trainingDataRoot, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 879,
     "status": "ok",
     "timestamp": 1611704623618,
     "user": {
      "displayName": "Jay Wang",
      "photoUrl": "",
      "userId": "08806282010227278078"
     },
     "user_tz": -780
    },
    "id": "Q3xNjjnuqKh7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2003-11-24',\n",
       " '2005-11-08',\n",
       " '2007-12-20',\n",
       " '2009-07-15',\n",
       " '2010-09-03',\n",
       " '2011-01-27',\n",
       " '2011-02-21',\n",
       " '2011-06-13',\n",
       " '2011-12-23',\n",
       " '2012-07-03',\n",
       " '2012-12-07',\n",
       " '2013-07-18',\n",
       " '2013-08-16',\n",
       " '2014-01-20',\n",
       " '2015-01-05',\n",
       " '2015-04-24',\n",
       " '2015-10-12',\n",
       " '2016-02-09',\n",
       " '2016-02-14',\n",
       " '2016-11-13',\n",
       " '2016-11-22',\n",
       " '2016-12-04',\n",
       " '2016-12-29',\n",
       " '2018-10-30',\n",
       " '2019-06-08',\n",
       " '2019-10-01']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingDataFolder = sorted( [ o for o in os.listdir( trainingDataRoot ) if os.path.isdir( os.path.join( trainingDataRoot, o ) )], reverse=False )\n",
    "trainingDataFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1095,
     "status": "ok",
     "timestamp": 1611704625859,
     "user": {
      "displayName": "Jay Wang",
      "photoUrl": "",
      "userId": "08806282010227278078"
     },
     "user_tz": -780
    },
    "id": "Fky1PTfnrFso"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2003-11-03.npy',\n",
       "  '2003-11-04.npy',\n",
       "  '2003-11-05.npy',\n",
       "  '2003-11-06.npy',\n",
       "  '2003-11-07.npy',\n",
       "  '2003-11-08.npy',\n",
       "  '2003-11-09.npy',\n",
       "  '2003-11-10.npy',\n",
       "  '2003-11-11.npy',\n",
       "  '2003-11-12.npy',\n",
       "  '2003-11-13.npy',\n",
       "  '2003-11-14.npy',\n",
       "  '2003-11-15.npy',\n",
       "  '2003-11-16.npy',\n",
       "  '2003-11-17.npy',\n",
       "  '2003-11-18.npy',\n",
       "  '2003-11-19.npy',\n",
       "  '2003-11-20.npy',\n",
       "  '2003-11-21.npy',\n",
       "  '2003-11-22.npy',\n",
       "  '2003-11-23.npy',\n",
       "  '2003-11-24.npy',\n",
       "  '2003-11-25.npy',\n",
       "  '2003-11-26.npy'],\n",
       " ['2005-10-18.npy',\n",
       "  '2005-10-19.npy',\n",
       "  '2005-10-20.npy',\n",
       "  '2005-10-21.npy',\n",
       "  '2005-10-22.npy',\n",
       "  '2005-10-23.npy',\n",
       "  '2005-10-24.npy',\n",
       "  '2005-10-25.npy',\n",
       "  '2005-10-26.npy',\n",
       "  '2005-10-27.npy',\n",
       "  '2005-10-28.npy',\n",
       "  '2005-10-29.npy',\n",
       "  '2005-10-30.npy',\n",
       "  '2005-10-31.npy',\n",
       "  '2005-11-01.npy',\n",
       "  '2005-11-02.npy',\n",
       "  '2005-11-03.npy',\n",
       "  '2005-11-04.npy',\n",
       "  '2005-11-05.npy',\n",
       "  '2005-11-06.npy',\n",
       "  '2005-11-07.npy',\n",
       "  '2005-11-08.npy',\n",
       "  '2005-11-09.npy',\n",
       "  '2005-11-10.npy'],\n",
       " ['2007-11-29.npy',\n",
       "  '2007-11-30.npy',\n",
       "  '2007-12-01.npy',\n",
       "  '2007-12-02.npy',\n",
       "  '2007-12-03.npy',\n",
       "  '2007-12-04.npy',\n",
       "  '2007-12-05.npy',\n",
       "  '2007-12-06.npy',\n",
       "  '2007-12-07.npy',\n",
       "  '2007-12-08.npy',\n",
       "  '2007-12-09.npy',\n",
       "  '2007-12-10.npy',\n",
       "  '2007-12-11.npy',\n",
       "  '2007-12-12.npy',\n",
       "  '2007-12-13.npy',\n",
       "  '2007-12-14.npy',\n",
       "  '2007-12-15.npy',\n",
       "  '2007-12-16.npy',\n",
       "  '2007-12-17.npy',\n",
       "  '2007-12-18.npy',\n",
       "  '2007-12-19.npy',\n",
       "  '2007-12-20.npy',\n",
       "  '2007-12-21.npy',\n",
       "  '2007-12-22.npy'],\n",
       " ['2009-06-24.npy',\n",
       "  '2009-06-25.npy',\n",
       "  '2009-06-26.npy',\n",
       "  '2009-06-27.npy',\n",
       "  '2009-06-28.npy',\n",
       "  '2009-06-29.npy',\n",
       "  '2009-06-30.npy',\n",
       "  '2009-07-01.npy',\n",
       "  '2009-07-02.npy',\n",
       "  '2009-07-03.npy',\n",
       "  '2009-07-04.npy',\n",
       "  '2009-07-05.npy',\n",
       "  '2009-07-06.npy',\n",
       "  '2009-07-07.npy',\n",
       "  '2009-07-08.npy',\n",
       "  '2009-07-09.npy',\n",
       "  '2009-07-10.npy',\n",
       "  '2009-07-11.npy',\n",
       "  '2009-07-12.npy',\n",
       "  '2009-07-13.npy',\n",
       "  '2009-07-14.npy',\n",
       "  '2009-07-15.npy',\n",
       "  '2009-07-16.npy',\n",
       "  '2009-07-17.npy'],\n",
       " ['2010-08-13.npy',\n",
       "  '2010-08-14.npy',\n",
       "  '2010-08-15.npy',\n",
       "  '2010-08-16.npy',\n",
       "  '2010-08-17.npy',\n",
       "  '2010-08-18.npy',\n",
       "  '2010-08-19.npy',\n",
       "  '2010-08-20.npy',\n",
       "  '2010-08-21.npy',\n",
       "  '2010-08-22.npy',\n",
       "  '2010-08-23.npy',\n",
       "  '2010-08-24.npy',\n",
       "  '2010-08-25.npy',\n",
       "  '2010-08-26.npy',\n",
       "  '2010-08-27.npy',\n",
       "  '2010-08-28.npy',\n",
       "  '2010-08-29.npy',\n",
       "  '2010-08-30.npy',\n",
       "  '2010-08-31.npy',\n",
       "  '2010-09-01.npy',\n",
       "  '2010-09-02.npy',\n",
       "  '2010-09-03.npy',\n",
       "  '2010-09-04.npy',\n",
       "  '2010-09-05.npy'],\n",
       " ['2011-01-06.npy',\n",
       "  '2011-01-07.npy',\n",
       "  '2011-01-08.npy',\n",
       "  '2011-01-09.npy',\n",
       "  '2011-01-10.npy',\n",
       "  '2011-01-11.npy',\n",
       "  '2011-01-12.npy',\n",
       "  '2011-01-13.npy',\n",
       "  '2011-01-14.npy',\n",
       "  '2011-01-15.npy',\n",
       "  '2011-01-16.npy',\n",
       "  '2011-01-17.npy',\n",
       "  '2011-01-18.npy',\n",
       "  '2011-01-19.npy',\n",
       "  '2011-01-20.npy',\n",
       "  '2011-01-21.npy',\n",
       "  '2011-01-22.npy',\n",
       "  '2011-01-23.npy',\n",
       "  '2011-01-24.npy',\n",
       "  '2011-01-25.npy',\n",
       "  '2011-01-26.npy',\n",
       "  '2011-01-27.npy',\n",
       "  '2011-01-28.npy',\n",
       "  '2011-01-29.npy'],\n",
       " ['2011-01-31.npy',\n",
       "  '2011-02-01.npy',\n",
       "  '2011-02-02.npy',\n",
       "  '2011-02-03.npy',\n",
       "  '2011-02-04.npy',\n",
       "  '2011-02-05.npy',\n",
       "  '2011-02-06.npy',\n",
       "  '2011-02-07.npy',\n",
       "  '2011-02-08.npy',\n",
       "  '2011-02-09.npy',\n",
       "  '2011-02-10.npy',\n",
       "  '2011-02-11.npy',\n",
       "  '2011-02-12.npy',\n",
       "  '2011-02-13.npy',\n",
       "  '2011-02-14.npy',\n",
       "  '2011-02-15.npy',\n",
       "  '2011-02-16.npy',\n",
       "  '2011-02-17.npy',\n",
       "  '2011-02-18.npy',\n",
       "  '2011-02-19.npy',\n",
       "  '2011-02-20.npy',\n",
       "  '2011-02-21.npy',\n",
       "  '2011-02-22.npy',\n",
       "  '2011-02-23.npy'],\n",
       " ['2011-05-23.npy',\n",
       "  '2011-05-24.npy',\n",
       "  '2011-05-25.npy',\n",
       "  '2011-05-26.npy',\n",
       "  '2011-05-27.npy',\n",
       "  '2011-05-28.npy',\n",
       "  '2011-05-29.npy',\n",
       "  '2011-05-30.npy',\n",
       "  '2011-05-31.npy',\n",
       "  '2011-06-01.npy',\n",
       "  '2011-06-02.npy',\n",
       "  '2011-06-03.npy',\n",
       "  '2011-06-04.npy',\n",
       "  '2011-06-05.npy',\n",
       "  '2011-06-06.npy',\n",
       "  '2011-06-07.npy',\n",
       "  '2011-06-08.npy',\n",
       "  '2011-06-09.npy',\n",
       "  '2011-06-10.npy',\n",
       "  '2011-06-11.npy',\n",
       "  '2011-06-12.npy',\n",
       "  '2011-06-13.npy',\n",
       "  '2011-06-14.npy',\n",
       "  '2011-06-15.npy'],\n",
       " ['2011-12-02.npy',\n",
       "  '2011-12-03.npy',\n",
       "  '2011-12-04.npy',\n",
       "  '2011-12-05.npy',\n",
       "  '2011-12-06.npy',\n",
       "  '2011-12-07.npy',\n",
       "  '2011-12-08.npy',\n",
       "  '2011-12-09.npy',\n",
       "  '2011-12-10.npy',\n",
       "  '2011-12-11.npy',\n",
       "  '2011-12-12.npy',\n",
       "  '2011-12-13.npy',\n",
       "  '2011-12-14.npy',\n",
       "  '2011-12-15.npy',\n",
       "  '2011-12-16.npy',\n",
       "  '2011-12-17.npy',\n",
       "  '2011-12-18.npy',\n",
       "  '2011-12-19.npy',\n",
       "  '2011-12-20.npy',\n",
       "  '2011-12-21.npy',\n",
       "  '2011-12-22.npy',\n",
       "  '2011-12-23.npy',\n",
       "  '2011-12-24.npy',\n",
       "  '2011-12-25.npy'],\n",
       " ['2012-06-12.npy',\n",
       "  '2012-06-13.npy',\n",
       "  '2012-06-14.npy',\n",
       "  '2012-06-15.npy',\n",
       "  '2012-06-16.npy',\n",
       "  '2012-06-17.npy',\n",
       "  '2012-06-18.npy',\n",
       "  '2012-06-19.npy',\n",
       "  '2012-06-20.npy',\n",
       "  '2012-06-21.npy',\n",
       "  '2012-06-22.npy',\n",
       "  '2012-06-23.npy',\n",
       "  '2012-06-24.npy',\n",
       "  '2012-06-25.npy',\n",
       "  '2012-06-26.npy',\n",
       "  '2012-06-27.npy',\n",
       "  '2012-06-28.npy',\n",
       "  '2012-06-29.npy',\n",
       "  '2012-06-30.npy',\n",
       "  '2012-07-01.npy',\n",
       "  '2012-07-02.npy',\n",
       "  '2012-07-03.npy',\n",
       "  '2012-07-04.npy',\n",
       "  '2012-07-05.npy'],\n",
       " ['2012-11-16.npy',\n",
       "  '2012-11-17.npy',\n",
       "  '2012-11-18.npy',\n",
       "  '2012-11-19.npy',\n",
       "  '2012-11-20.npy',\n",
       "  '2012-11-21.npy',\n",
       "  '2012-11-22.npy',\n",
       "  '2012-11-23.npy',\n",
       "  '2012-11-24.npy',\n",
       "  '2012-11-25.npy',\n",
       "  '2012-11-26.npy',\n",
       "  '2012-11-27.npy',\n",
       "  '2012-11-28.npy',\n",
       "  '2012-11-29.npy',\n",
       "  '2012-11-30.npy',\n",
       "  '2012-12-01.npy',\n",
       "  '2012-12-02.npy',\n",
       "  '2012-12-03.npy',\n",
       "  '2012-12-04.npy',\n",
       "  '2012-12-05.npy',\n",
       "  '2012-12-06.npy',\n",
       "  '2012-12-07.npy',\n",
       "  '2012-12-08.npy',\n",
       "  '2012-12-09.npy'],\n",
       " ['2013-06-27.npy',\n",
       "  '2013-06-28.npy',\n",
       "  '2013-06-29.npy',\n",
       "  '2013-06-30.npy',\n",
       "  '2013-07-01.npy',\n",
       "  '2013-07-02.npy',\n",
       "  '2013-07-03.npy',\n",
       "  '2013-07-04.npy',\n",
       "  '2013-07-05.npy',\n",
       "  '2013-07-06.npy',\n",
       "  '2013-07-07.npy',\n",
       "  '2013-07-08.npy',\n",
       "  '2013-07-09.npy',\n",
       "  '2013-07-10.npy',\n",
       "  '2013-07-11.npy',\n",
       "  '2013-07-12.npy',\n",
       "  '2013-07-13.npy',\n",
       "  '2013-07-14.npy',\n",
       "  '2013-07-15.npy',\n",
       "  '2013-07-16.npy',\n",
       "  '2013-07-17.npy',\n",
       "  '2013-07-18.npy',\n",
       "  '2013-07-19.npy',\n",
       "  '2013-07-20.npy'],\n",
       " ['2013-07-26.npy',\n",
       "  '2013-07-27.npy',\n",
       "  '2013-07-28.npy',\n",
       "  '2013-07-29.npy',\n",
       "  '2013-07-30.npy',\n",
       "  '2013-07-31.npy',\n",
       "  '2013-08-01.npy',\n",
       "  '2013-08-02.npy',\n",
       "  '2013-08-03.npy',\n",
       "  '2013-08-04.npy',\n",
       "  '2013-08-05.npy',\n",
       "  '2013-08-06.npy',\n",
       "  '2013-08-07.npy',\n",
       "  '2013-08-08.npy',\n",
       "  '2013-08-09.npy',\n",
       "  '2013-08-10.npy',\n",
       "  '2013-08-11.npy',\n",
       "  '2013-08-12.npy',\n",
       "  '2013-08-13.npy',\n",
       "  '2013-08-14.npy',\n",
       "  '2013-08-15.npy',\n",
       "  '2013-08-16.npy',\n",
       "  '2013-08-17.npy',\n",
       "  '2013-08-18.npy'],\n",
       " ['2013-12-30.npy',\n",
       "  '2013-12-31.npy',\n",
       "  '2014-01-01.npy',\n",
       "  '2014-01-02.npy',\n",
       "  '2014-01-03.npy',\n",
       "  '2014-01-04.npy',\n",
       "  '2014-01-05.npy',\n",
       "  '2014-01-06.npy',\n",
       "  '2014-01-07.npy',\n",
       "  '2014-01-08.npy',\n",
       "  '2014-01-09.npy',\n",
       "  '2014-01-10.npy',\n",
       "  '2014-01-11.npy',\n",
       "  '2014-01-12.npy',\n",
       "  '2014-01-13.npy',\n",
       "  '2014-01-14.npy',\n",
       "  '2014-01-15.npy',\n",
       "  '2014-01-16.npy',\n",
       "  '2014-01-17.npy',\n",
       "  '2014-01-18.npy',\n",
       "  '2014-01-19.npy',\n",
       "  '2014-01-20.npy',\n",
       "  '2014-01-21.npy',\n",
       "  '2014-01-22.npy'],\n",
       " ['2014-12-15.npy',\n",
       "  '2014-12-16.npy',\n",
       "  '2014-12-17.npy',\n",
       "  '2014-12-18.npy',\n",
       "  '2014-12-19.npy',\n",
       "  '2014-12-20.npy',\n",
       "  '2014-12-21.npy',\n",
       "  '2014-12-22.npy',\n",
       "  '2014-12-23.npy',\n",
       "  '2014-12-24.npy',\n",
       "  '2014-12-25.npy',\n",
       "  '2014-12-26.npy',\n",
       "  '2014-12-27.npy',\n",
       "  '2014-12-28.npy',\n",
       "  '2014-12-29.npy',\n",
       "  '2014-12-30.npy',\n",
       "  '2014-12-31.npy',\n",
       "  '2015-01-01.npy',\n",
       "  '2015-01-02.npy',\n",
       "  '2015-01-03.npy',\n",
       "  '2015-01-04.npy',\n",
       "  '2015-01-05.npy',\n",
       "  '2015-01-06.npy',\n",
       "  '2015-01-07.npy'],\n",
       " ['2015-04-03.npy',\n",
       "  '2015-04-04.npy',\n",
       "  '2015-04-05.npy',\n",
       "  '2015-04-06.npy',\n",
       "  '2015-04-07.npy',\n",
       "  '2015-04-08.npy',\n",
       "  '2015-04-09.npy',\n",
       "  '2015-04-10.npy',\n",
       "  '2015-04-11.npy',\n",
       "  '2015-04-12.npy',\n",
       "  '2015-04-13.npy',\n",
       "  '2015-04-14.npy',\n",
       "  '2015-04-15.npy',\n",
       "  '2015-04-16.npy',\n",
       "  '2015-04-17.npy',\n",
       "  '2015-04-18.npy',\n",
       "  '2015-04-19.npy',\n",
       "  '2015-04-20.npy',\n",
       "  '2015-04-21.npy',\n",
       "  '2015-04-22.npy',\n",
       "  '2015-04-23.npy',\n",
       "  '2015-04-24.npy',\n",
       "  '2015-04-25.npy',\n",
       "  '2015-04-26.npy'],\n",
       " ['2015-09-21.npy',\n",
       "  '2015-09-22.npy',\n",
       "  '2015-09-23.npy',\n",
       "  '2015-09-24.npy',\n",
       "  '2015-09-25.npy',\n",
       "  '2015-09-26.npy',\n",
       "  '2015-09-27.npy',\n",
       "  '2015-09-28.npy',\n",
       "  '2015-09-29.npy',\n",
       "  '2015-09-30.npy',\n",
       "  '2015-10-01.npy',\n",
       "  '2015-10-02.npy',\n",
       "  '2015-10-03.npy',\n",
       "  '2015-10-04.npy',\n",
       "  '2015-10-05.npy',\n",
       "  '2015-10-06.npy',\n",
       "  '2015-10-07.npy',\n",
       "  '2015-10-08.npy',\n",
       "  '2015-10-09.npy',\n",
       "  '2015-10-10.npy',\n",
       "  '2015-10-11.npy',\n",
       "  '2015-10-12.npy',\n",
       "  '2015-10-13.npy',\n",
       "  '2015-10-14.npy'],\n",
       " ['2016-01-19.npy',\n",
       "  '2016-01-20.npy',\n",
       "  '2016-01-21.npy',\n",
       "  '2016-01-22.npy',\n",
       "  '2016-01-23.npy',\n",
       "  '2016-01-24.npy',\n",
       "  '2016-01-25.npy',\n",
       "  '2016-01-26.npy',\n",
       "  '2016-01-27.npy',\n",
       "  '2016-01-28.npy',\n",
       "  '2016-01-29.npy',\n",
       "  '2016-01-30.npy',\n",
       "  '2016-01-31.npy',\n",
       "  '2016-02-01.npy',\n",
       "  '2016-02-02.npy',\n",
       "  '2016-02-03.npy',\n",
       "  '2016-02-04.npy',\n",
       "  '2016-02-05.npy',\n",
       "  '2016-02-06.npy',\n",
       "  '2016-02-07.npy',\n",
       "  '2016-02-08.npy',\n",
       "  '2016-02-09.npy',\n",
       "  '2016-02-10.npy',\n",
       "  '2016-02-11.npy'],\n",
       " ['2016-01-24.npy',\n",
       "  '2016-01-25.npy',\n",
       "  '2016-01-26.npy',\n",
       "  '2016-01-27.npy',\n",
       "  '2016-01-28.npy',\n",
       "  '2016-01-29.npy',\n",
       "  '2016-01-30.npy',\n",
       "  '2016-01-31.npy',\n",
       "  '2016-02-01.npy',\n",
       "  '2016-02-02.npy',\n",
       "  '2016-02-03.npy',\n",
       "  '2016-02-04.npy',\n",
       "  '2016-02-05.npy',\n",
       "  '2016-02-06.npy',\n",
       "  '2016-02-07.npy',\n",
       "  '2016-02-08.npy',\n",
       "  '2016-02-09.npy',\n",
       "  '2016-02-10.npy',\n",
       "  '2016-02-11.npy',\n",
       "  '2016-02-12.npy',\n",
       "  '2016-02-13.npy',\n",
       "  '2016-02-14.npy',\n",
       "  '2016-02-15.npy',\n",
       "  '2016-02-16.npy'],\n",
       " ['2016-10-23.npy',\n",
       "  '2016-10-24.npy',\n",
       "  '2016-10-25.npy',\n",
       "  '2016-10-26.npy',\n",
       "  '2016-10-27.npy',\n",
       "  '2016-10-28.npy',\n",
       "  '2016-10-29.npy',\n",
       "  '2016-10-30.npy',\n",
       "  '2016-10-31.npy',\n",
       "  '2016-11-01.npy',\n",
       "  '2016-11-02.npy',\n",
       "  '2016-11-03.npy',\n",
       "  '2016-11-04.npy',\n",
       "  '2016-11-05.npy',\n",
       "  '2016-11-06.npy',\n",
       "  '2016-11-07.npy',\n",
       "  '2016-11-08.npy',\n",
       "  '2016-11-09.npy',\n",
       "  '2016-11-10.npy',\n",
       "  '2016-11-11.npy',\n",
       "  '2016-11-12.npy',\n",
       "  '2016-11-13.npy',\n",
       "  '2016-11-14.npy',\n",
       "  '2016-11-15.npy'],\n",
       " ['2016-11-01.npy',\n",
       "  '2016-11-02.npy',\n",
       "  '2016-11-03.npy',\n",
       "  '2016-11-04.npy',\n",
       "  '2016-11-05.npy',\n",
       "  '2016-11-06.npy',\n",
       "  '2016-11-07.npy',\n",
       "  '2016-11-08.npy',\n",
       "  '2016-11-09.npy',\n",
       "  '2016-11-10.npy',\n",
       "  '2016-11-11.npy',\n",
       "  '2016-11-12.npy',\n",
       "  '2016-11-13.npy',\n",
       "  '2016-11-14.npy',\n",
       "  '2016-11-15.npy',\n",
       "  '2016-11-16.npy',\n",
       "  '2016-11-17.npy',\n",
       "  '2016-11-18.npy',\n",
       "  '2016-11-19.npy',\n",
       "  '2016-11-20.npy',\n",
       "  '2016-11-21.npy',\n",
       "  '2016-11-22.npy',\n",
       "  '2016-11-23.npy',\n",
       "  '2016-11-24.npy'],\n",
       " ['2016-11-13.npy',\n",
       "  '2016-11-14.npy',\n",
       "  '2016-11-15.npy',\n",
       "  '2016-11-16.npy',\n",
       "  '2016-11-17.npy',\n",
       "  '2016-11-18.npy',\n",
       "  '2016-11-19.npy',\n",
       "  '2016-11-20.npy',\n",
       "  '2016-11-21.npy',\n",
       "  '2016-11-22.npy',\n",
       "  '2016-11-23.npy',\n",
       "  '2016-11-24.npy',\n",
       "  '2016-11-25.npy',\n",
       "  '2016-11-26.npy',\n",
       "  '2016-11-27.npy',\n",
       "  '2016-11-28.npy',\n",
       "  '2016-11-29.npy',\n",
       "  '2016-11-30.npy',\n",
       "  '2016-12-01.npy',\n",
       "  '2016-12-02.npy',\n",
       "  '2016-12-03.npy',\n",
       "  '2016-12-04.npy',\n",
       "  '2016-12-05.npy',\n",
       "  '2016-12-06.npy'],\n",
       " ['2016-12-08.npy',\n",
       "  '2016-12-09.npy',\n",
       "  '2016-12-10.npy',\n",
       "  '2016-12-11.npy',\n",
       "  '2016-12-12.npy',\n",
       "  '2016-12-13.npy',\n",
       "  '2016-12-14.npy',\n",
       "  '2016-12-15.npy',\n",
       "  '2016-12-16.npy',\n",
       "  '2016-12-17.npy',\n",
       "  '2016-12-18.npy',\n",
       "  '2016-12-19.npy',\n",
       "  '2016-12-20.npy',\n",
       "  '2016-12-21.npy',\n",
       "  '2016-12-22.npy',\n",
       "  '2016-12-23.npy',\n",
       "  '2016-12-24.npy',\n",
       "  '2016-12-25.npy',\n",
       "  '2016-12-26.npy',\n",
       "  '2016-12-27.npy',\n",
       "  '2016-12-28.npy',\n",
       "  '2016-12-29.npy',\n",
       "  '2016-12-30.npy',\n",
       "  '2016-12-31.npy'],\n",
       " ['2018-10-05.npy',\n",
       "  '2018-10-06.npy',\n",
       "  '2018-10-08.npy',\n",
       "  '2018-10-09.npy',\n",
       "  '2018-10-10.npy',\n",
       "  '2018-10-11.npy',\n",
       "  '2018-10-12.npy',\n",
       "  '2018-10-13.npy',\n",
       "  '2018-10-15.npy',\n",
       "  '2018-10-16.npy',\n",
       "  '2018-10-17.npy',\n",
       "  '2018-10-18.npy',\n",
       "  '2018-10-19.npy',\n",
       "  '2018-10-20.npy',\n",
       "  '2018-10-22.npy',\n",
       "  '2018-10-23.npy',\n",
       "  '2018-10-24.npy',\n",
       "  '2018-10-25.npy',\n",
       "  '2018-10-26.npy',\n",
       "  '2018-10-27.npy',\n",
       "  '2018-10-29.npy',\n",
       "  '2018-10-30.npy',\n",
       "  '2018-10-31.npy',\n",
       "  '2018-11-01.npy'],\n",
       " ['2019-05-18.npy',\n",
       "  '2019-05-19.npy',\n",
       "  '2019-05-20.npy',\n",
       "  '2019-05-21.npy',\n",
       "  '2019-05-22.npy',\n",
       "  '2019-05-23.npy',\n",
       "  '2019-05-24.npy',\n",
       "  '2019-05-25.npy',\n",
       "  '2019-05-26.npy',\n",
       "  '2019-05-27.npy',\n",
       "  '2019-05-28.npy',\n",
       "  '2019-05-29.npy',\n",
       "  '2019-05-30.npy',\n",
       "  '2019-05-31.npy',\n",
       "  '2019-06-01.npy',\n",
       "  '2019-06-02.npy',\n",
       "  '2019-06-03.npy',\n",
       "  '2019-06-04.npy',\n",
       "  '2019-06-05.npy',\n",
       "  '2019-06-06.npy',\n",
       "  '2019-06-07.npy',\n",
       "  '2019-06-08.npy',\n",
       "  '2019-06-09.npy',\n",
       "  '2019-06-10.npy'],\n",
       " ['2019-09-10.npy',\n",
       "  '2019-09-11.npy',\n",
       "  '2019-09-12.npy',\n",
       "  '2019-09-13.npy',\n",
       "  '2019-09-14.npy',\n",
       "  '2019-09-15.npy',\n",
       "  '2019-09-16.npy',\n",
       "  '2019-09-17.npy',\n",
       "  '2019-09-18.npy',\n",
       "  '2019-09-19.npy',\n",
       "  '2019-09-20.npy',\n",
       "  '2019-09-21.npy',\n",
       "  '2019-09-22.npy',\n",
       "  '2019-09-23.npy',\n",
       "  '2019-09-24.npy',\n",
       "  '2019-09-25.npy',\n",
       "  '2019-09-26.npy',\n",
       "  '2019-09-27.npy',\n",
       "  '2019-09-28.npy',\n",
       "  '2019-09-29.npy',\n",
       "  '2019-09-30.npy',\n",
       "  '2019-10-01.npy',\n",
       "  '2019-10-02.npy',\n",
       "  '2019-10-03.npy']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingFileList = []\n",
    "for i in trainingDataFolder:\n",
    "  dayList = []\n",
    "  for o in sorted( os.listdir(os.path.join(trainingDataRoot, i)) ):\n",
    "    if o.endswith('.npy') and os.path.isfile( os.path.join( trainingDataRoot, i, o ) ):\n",
    "      dayList.append(o)\n",
    "  trainingFileList.append(dayList)\n",
    "trainingFileList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0j2A_IjvhZu-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2003-11-23',\n",
       " '2005-11-07',\n",
       " '2007-12-19',\n",
       " '2009-07-14',\n",
       " '2010-09-02',\n",
       " '2011-01-26',\n",
       " '2011-02-20',\n",
       " '2011-06-12',\n",
       " '2011-12-22',\n",
       " '2012-07-02',\n",
       " '2012-12-06',\n",
       " '2013-07-17',\n",
       " '2013-08-15',\n",
       " '2014-01-19',\n",
       " '2015-01-04',\n",
       " '2015-04-23',\n",
       " '2015-10-11',\n",
       " '2016-02-08',\n",
       " '2016-02-13',\n",
       " '2016-11-12',\n",
       " '2016-11-21',\n",
       " '2016-12-03',\n",
       " '2016-12-28',\n",
       " '2018-10-29',\n",
       " '2019-06-07',\n",
       " '2019-09-30']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneDayList = []\n",
    "for i in trainingDataFolder:\n",
    "    oneDay = datetime.datetime.strptime( i, '%Y-%m-%d' ) + datetime.timedelta( days=-1 )\n",
    "    oneDaystr = '{:04}-{:02}-{:02}'.format( oneDay.year, oneDay.month, oneDay.day )\n",
    "    oneDayList.append(oneDaystr)\n",
    "oneDayList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1015,
     "status": "ok",
     "timestamp": 1611704630240,
     "user": {
      "displayName": "Jay Wang",
      "photoUrl": "",
      "userId": "08806282010227278078"
     },
     "user_tz": -780
    },
    "id": "URWjUk7SlFlM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2003-11-22',\n",
       " '2005-11-06',\n",
       " '2007-12-18',\n",
       " '2009-07-13',\n",
       " '2010-09-01',\n",
       " '2011-01-25',\n",
       " '2011-02-19',\n",
       " '2011-06-11',\n",
       " '2011-12-21',\n",
       " '2012-07-01',\n",
       " '2012-12-05',\n",
       " '2013-07-16',\n",
       " '2013-08-14',\n",
       " '2014-01-18',\n",
       " '2015-01-03',\n",
       " '2015-04-22',\n",
       " '2015-10-10',\n",
       " '2016-02-07',\n",
       " '2016-02-12',\n",
       " '2016-11-11',\n",
       " '2016-11-20',\n",
       " '2016-12-02',\n",
       " '2016-12-27',\n",
       " '2018-10-28',\n",
       " '2019-06-06',\n",
       " '2019-09-29']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoDayList = []\n",
    "for i in trainingDataFolder:\n",
    "    twoDay = datetime.datetime.strptime( i, '%Y-%m-%d' ) + datetime.timedelta( days=-2 )\n",
    "    twoDaystr = '{:04}-{:02}-{:02}'.format( twoDay.year, twoDay.month, twoDay.day )\n",
    "    twoDayList.append(twoDaystr)\n",
    "twoDayList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3660,
     "status": "ok",
     "timestamp": 1611704634349,
     "user": {
      "displayName": "Jay Wang",
      "photoUrl": "",
      "userId": "08806282010227278078"
     },
     "user_tz": -780
    },
    "id": "UFBhFHZ2UpoB",
    "outputId": "d96abe91-8d49-4fa0-a9f6-153350645edd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(390, 10, 50, 50, 3)\n",
      "(390,)\n"
     ]
    }
   ],
   "source": [
    "trainingData = []\n",
    "trainingLabel = []\n",
    "for i, j in enumerate( trainingDataFolder ):\n",
    "  for m in range( len( trainingFileList[i] ) - 9 ):\n",
    "    sequenceData = []\n",
    "    validateData = []\n",
    "    for n in range ( 10 ):\n",
    "      with open( os.path.join(trainingDataRoot, j, trainingFileList[i][m +n] ), 'rb' ) as f:\n",
    "        sequenceData.append( list( np.load( f ) ) )\n",
    "        validateData.append(os.path.splitext( trainingFileList[i][m +n] )[0] )\n",
    "        #print( f'validateData:{validateData} {i, m +n}' )\n",
    "    trainingData.append( sequenceData )\n",
    "    if validateData[-1] in trainingDataFolder:\n",
    "      trainingLabel.append( 0.4 )\n",
    "    elif validateData[-1] in oneDayList or validateData[-2] in trainingDataFolder:\n",
    "      trainingLabel.append( 0.25 )\n",
    "    elif validateData[-1] in twoDayList or validateData[-3] in trainingDataFolder:\n",
    "      trainingLabel.append( 0.05 )\n",
    "    else:\n",
    "      trainingLabel.append(0)\n",
    "train_X = np.array( trainingData, dtype=np.float32 )\n",
    "print( train_X.shape )\n",
    "train_y = np.array( trainingLabel, dtype=np.float32 )\n",
    "print( train_y.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 855,
     "status": "ok",
     "timestamp": 1611704644148,
     "user": {
      "displayName": "Jay Wang",
      "photoUrl": "",
      "userId": "08806282010227278078"
     },
     "user_tz": -780
    },
    "id": "LbqigABI-04v",
    "outputId": "82334a7e-d7a6-44dc-ae72-c6eed29303d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05,\n",
       "       0.25, 0.4 , 0.25, 0.05, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.05, 0.25, 0.4 , 0.25, 0.05, 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.25, 0.4 , 0.25,\n",
       "       0.05, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.05, 0.25, 0.4 , 0.25, 0.05, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.05, 0.25, 0.4 , 0.25, 0.05, 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.25, 0.4 ,\n",
       "       0.25, 0.05, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.05, 0.25, 0.4 , 0.25, 0.05, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.25, 0.4 , 0.25, 0.05, 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.25,\n",
       "       0.4 , 0.25, 0.05, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.05, 0.25, 0.4 , 0.25, 0.05, 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.25, 0.4 , 0.25, 0.05,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05,\n",
       "       0.25, 0.4 , 0.25, 0.05, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.05, 0.25, 0.4 , 0.25, 0.05, 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.25, 0.4 , 0.25,\n",
       "       0.05, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.05, 0.25, 0.4 , 0.25, 0.05, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.05, 0.25, 0.4 , 0.25, 0.05, 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.25, 0.4 ,\n",
       "       0.25, 0.05, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.05, 0.25, 0.4 , 0.25, 0.05, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.05, 0.25, 0.4 , 0.25, 0.05, 0.05, 0.25, 0.4 , 0.25, 0.05, 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.25,\n",
       "       0.4 , 0.25, 0.05, 0.  , 0.05, 0.25, 0.4 , 0.25, 0.05, 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.05, 0.25, 0.4 , 0.25, 0.05, 0.4 , 0.25, 0.05, 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.25, 0.4 , 0.25, 0.05,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05,\n",
       "       0.25, 0.4 , 0.25, 0.05, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.25, 0.4 , 0.25, 0.05, 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.25, 0.4 , 0.25,\n",
       "       0.05, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.05, 0.25, 0.4 , 0.25, 0.05], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "executionInfo": {
     "elapsed": 823,
     "status": "ok",
     "timestamp": 1611704648274,
     "user": {
      "displayName": "Jay Wang",
      "photoUrl": "",
      "userId": "08806282010227278078"
     },
     "user_tz": -780
    },
    "id": "eb85ySPeVl0s"
   },
   "outputs": [],
   "source": [
    "testDataRoot = '../TestData'\n",
    "#testFileList = [f for f in os.listdir(testDataRoot) if f.endswith('.npy') and os.path.isfile(os.path.join(testDataRoot, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 998,
     "status": "ok",
     "timestamp": 1611704649807,
     "user": {
      "displayName": "Jay Wang",
      "photoUrl": "",
      "userId": "08806282010227278078"
     },
     "user_tz": -780
    },
    "id": "naYHLjtLAmns",
    "outputId": "5677f11c-80fa-4662-c41f-772bf2a16096"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2013-12-16', '2015-05-04', '2017-10-22']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataFolder = sorted( [ o for o in os.listdir( testDataRoot ) if os.path.isdir( os.path.join( testDataRoot, o ) )], reverse=False )\n",
    "testDataFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1087,
     "status": "ok",
     "timestamp": 1611704652050,
     "user": {
      "displayName": "Jay Wang",
      "photoUrl": "",
      "userId": "08806282010227278078"
     },
     "user_tz": -780
    },
    "id": "YI-XwBiWAOJh",
    "outputId": "b1da7c21-1e7e-46a0-d075-601793da6408"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2013-11-25.npy',\n",
       "  '2013-11-26.npy',\n",
       "  '2013-11-27.npy',\n",
       "  '2013-11-28.npy',\n",
       "  '2013-11-29.npy',\n",
       "  '2013-11-30.npy',\n",
       "  '2013-12-01.npy',\n",
       "  '2013-12-02.npy',\n",
       "  '2013-12-03.npy',\n",
       "  '2013-12-04.npy',\n",
       "  '2013-12-05.npy',\n",
       "  '2013-12-06.npy',\n",
       "  '2013-12-07.npy',\n",
       "  '2013-12-08.npy',\n",
       "  '2013-12-09.npy',\n",
       "  '2013-12-10.npy',\n",
       "  '2013-12-11.npy',\n",
       "  '2013-12-12.npy',\n",
       "  '2013-12-13.npy',\n",
       "  '2013-12-14.npy',\n",
       "  '2013-12-15.npy',\n",
       "  '2013-12-16.npy',\n",
       "  '2013-12-17.npy',\n",
       "  '2013-12-18.npy'],\n",
       " ['2015-04-13.npy',\n",
       "  '2015-04-14.npy',\n",
       "  '2015-04-15.npy',\n",
       "  '2015-04-16.npy',\n",
       "  '2015-04-17.npy',\n",
       "  '2015-04-18.npy',\n",
       "  '2015-04-19.npy',\n",
       "  '2015-04-20.npy',\n",
       "  '2015-04-21.npy',\n",
       "  '2015-04-22.npy',\n",
       "  '2015-04-23.npy',\n",
       "  '2015-04-24.npy',\n",
       "  '2015-04-25.npy',\n",
       "  '2015-04-26.npy',\n",
       "  '2015-04-27.npy',\n",
       "  '2015-04-28.npy',\n",
       "  '2015-04-29.npy',\n",
       "  '2015-04-30.npy',\n",
       "  '2015-05-01.npy',\n",
       "  '2015-05-02.npy',\n",
       "  '2015-05-03.npy',\n",
       "  '2015-05-04.npy',\n",
       "  '2015-05-05.npy',\n",
       "  '2015-05-06.npy'],\n",
       " ['2017-10-01.npy',\n",
       "  '2017-10-02.npy',\n",
       "  '2017-10-03.npy',\n",
       "  '2017-10-04.npy',\n",
       "  '2017-10-05.npy',\n",
       "  '2017-10-06.npy',\n",
       "  '2017-10-07.npy',\n",
       "  '2017-10-08.npy',\n",
       "  '2017-10-09.npy',\n",
       "  '2017-10-10.npy',\n",
       "  '2017-10-11.npy',\n",
       "  '2017-10-12.npy',\n",
       "  '2017-10-13.npy',\n",
       "  '2017-10-14.npy',\n",
       "  '2017-10-15.npy',\n",
       "  '2017-10-16.npy',\n",
       "  '2017-10-17.npy',\n",
       "  '2017-10-18.npy',\n",
       "  '2017-10-19.npy',\n",
       "  '2017-10-20.npy',\n",
       "  '2017-10-21.npy',\n",
       "  '2017-10-22.npy',\n",
       "  '2017-10-23.npy',\n",
       "  '2017-10-24.npy']]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFileList = []\n",
    "for i in testDataFolder:\n",
    "  dayList = []\n",
    "  for o in sorted( os.listdir( os.path.join(testDataRoot, i ) ) ):\n",
    "    if o.endswith( '.npy' ) and os.path.isfile( os.path.join( testDataRoot, i, o ) ):\n",
    "      dayList.append( o )\n",
    "  testFileList.append( dayList )\n",
    "testFileList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1218,
     "status": "ok",
     "timestamp": 1611704656481,
     "user": {
      "displayName": "Jay Wang",
      "photoUrl": "",
      "userId": "08806282010227278078"
     },
     "user_tz": -780
    },
    "id": "AZgujQHBd26-",
    "outputId": "cca41226-b074-466a-cdf3-a4d742ea047d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 10, 50, 50, 3)\n",
      "(45,)\n"
     ]
    }
   ],
   "source": [
    "testData = []\n",
    "testLabel = []\n",
    "for i, j in enumerate( testDataFolder ):\n",
    "  for m in range( len( testFileList[i] ) - 9 ):\n",
    "    sequenceData = []\n",
    "    validateData = []\n",
    "    for n in range ( 10 ):\n",
    "      with open( os.path.join( testDataRoot, j, testFileList[i][m +n] ), 'rb') as f:\n",
    "        sequenceData.append( list( np.load( f ) ) )\n",
    "        validateData.append( os.path.splitext( testFileList[i][m +n] )[0] )\n",
    "        #print( f'validateData:{validateData} {i, m +n}' )\n",
    "    testData.append( sequenceData )\n",
    "    twoDay = datetime.datetime.strptime( j, '%Y-%m-%d' ) + datetime.timedelta( days=-2 )\n",
    "    twoDaystr = '{:04}-{:02}-{:02}'.format( twoDay.year, twoDay.month, twoDay.day )\n",
    "    oneDay = datetime.datetime.strptime( j, '%Y-%m-%d' ) + datetime.timedelta( days=-1 )\n",
    "    oneDaystr = '{:04}-{:02}-{:02}'.format( oneDay.year, oneDay.month, oneDay.day )\n",
    "    if validateData[-1] == j:\n",
    "      testLabel.append( 0.4 )\n",
    "    elif validateData[-1] == twoDaystr or validateData[-3] == j:\n",
    "      testLabel.append( 0.05 )\n",
    "    elif validateData[-1] == oneDaystr or validateData[-2] == j:\n",
    "      testLabel.append( 0.25 )\n",
    "    else:\n",
    "      testLabel.append(0)\n",
    "test_X = np.array( testData, dtype=np.float32 )\n",
    "print( test_X.shape )\n",
    "test_y = np.array( testLabel, dtype=np.float32 )\n",
    "print( test_y.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 842,
     "status": "ok",
     "timestamp": 1611704659938,
     "user": {
      "displayName": "Jay Wang",
      "photoUrl": "",
      "userId": "08806282010227278078"
     },
     "user_tz": -780
    },
    "id": "I2evj6rN-ETD",
    "outputId": "4f6b733b-582d-416f-e3a1-4cff354f46bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05,\n",
       "       0.25, 0.4 , 0.25, 0.05, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.05, 0.25, 0.4 , 0.25, 0.05, 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.25, 0.4 , 0.25,\n",
       "       0.05], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, n=248 (63.590%)\n",
      "Class=1, n=56 (14.359%)\n",
      "Class=2, n=57 (14.615%)\n",
      "Class=3, n=29 (7.436%)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAHwCAYAAADATlvnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAABYlAAAWJQFJUiTwAAAizUlEQVR4nO3de7BlVX0n8O9PCKAYGnCSoGYmLY4Iha8RDYoziFhxMBqfOPJHDHE0xgQ1KEzFEk3aRKtIwfjEaEqNEJkaTGFpSsRHSkBQJnHSxDCUKIpcjU8krY08JEHW/HH2lcvl3O57+557z133fD5Vp1afvddee+/Vq7u/d/V+VGstAABAH+4z7QMAAACWT4AHAICOCPAAANARAR4AADoiwAMAQEcEeAAA6IgADwAAHRHgAQCgIwI8AAB0RIAHAICOCPAAANARAR4AADqy97QPYKOoqhuSHJBkbsqHAgDA5rU1yc2ttYfsaQMC/N0OuO9973vwEUcccfC0DwQAgM3p2muvze23376qNgT4u80dccQRB2/fvn3axwEAwCZ11FFH5aqrrppbTRuugQcAgI4I8AAA0BEBHgAAOiLAAwBARwR4AADoiAAPAAAdEeABAKAjAjwAAHREgAcAgI6sOsBX1QOq6qVV9ZGq+lpV3V5VO6vqc1X1kqq6z6L6W6uq7eJzwS72dXJVfaGqbhn2cVlVPXO15wAAAL3YewJtvCDJu5N8N8mlSb6Z5JeSPC/J+5I8vape0Fpri7b7pyQfHdPeNeN2UlVnJzktybeSvDfJPklOSvKxqnpla+2c1Z8KAABsbJMI8NcleVaSj7fW7ppfWFWvS/KFJM/PKMx/eNF2X2ytbVvODqrqmIzC+/VJHt9a++Gw/Kwk25OcXVUXtdbmVncqAACwsa36EprW2iWttY8tDO/D8u8lec/w9bhV7ublQ/nm+fA+7GMuybuS7JvkxavcBwAAbHhrfRPrvw3lnWPWPaiqfreqXjeUj9pFO8cP5SfHrPvEojoAALBpTeISmrGqau8kvzV8HRe8f234LNzmsiQnt9a+uWDZ/kkenOSW1tp3x7Tz1aE8bJnHtX2JVYcvZ3sAAJimtZyBPzPJI5Jc3Fr71ILltyX50yRHJTlo+Dw5oxtgj0vymSG0z9sylDuX2M/88gMnctQAALCBrckMfFW9KqObTr+c5EUL17XWbkzyR4s2ubyqnpbkc0mOTvLSJG9f4W4XP+VmfKXWjlrimLcneewK9wkAAOtq4jPwVXVKRuH7S0me0lrbsZztWmt3ZvTYySQ5dsGq+Rn2LRlvdzP0AACwaUx0Br6qTk3y1oye5f7UYbZ9JX4wlD+7hKa1dmtVfTvJg6vqgWOug3/YUF63B4e8IWx97cenfQhM0dyZz5j2IQAAHZnYDHxV/WFG4f2LGc28rzS8J8kThvLri5ZfMpQnjNnm6YvqAADApjWRAF9Vb8joptXtGc2837SLukdX1T5jlh+f5NXD1/MXrZ5/nvwZVXXQgm22JjklyR1JPrDHJwAAAJ1Y9SU0VXVykj9J8tMkVyR5VVUtrjbXWjt3+PWfJTlyeGTkt4Zlj8rdz3F/Q2vtyoUbt9aurKq3JHlNkqur6sIk+yR5YZKDk7zSW1gBAJgFk7gG/iFDuVeSU5eo89kk5w6//mCS5yZ5fEaXv/xcku8n+esk57TWrhjXQGvttKq6OskrkrwsyV1JrkpyVmvtolWfBQAAdGDVAb61ti3JthXUf3+S9+/hvs5Lct6ebAsAAJvBWr7ICQAAmDABHgAAOiLAAwBARwR4AADoiAAPAAAdEeABAKAjAjwAAHREgAcAgI4I8AAA0BEBHgAAOiLAAwBARwR4AADoiAAPAAAdEeABAKAjAjwAAHREgAcAgI4I8AAA0BEBHgAAOiLAAwBARwR4AADoiAAPAAAdEeABAKAjAjwAAHREgAcAgI4I8AAA0BEBHgAAOiLAAwBARwR4AADoiAAPAAAdEeABAKAjAjwAAHREgAcAgI4I8AAA0BEBHgAAOiLAAwBARwR4AADoiAAPAAAdEeABAKAjAjwAAHREgAcAgI4I8AAA0BEBHgAAOiLAAwBARwR4AADoiAAPAAAdEeABAKAjAjwAAHREgAcAgI4I8AAA0BEBHgAAOiLAAwBARwR4AADoiAAPAAAdEeABAKAjAjwAAHREgAcAgI4I8AAA0BEBHgAAOiLAAwBARwR4AADoiAAPAAAdEeABAKAjAjwAAHREgAcAgI4I8AAA0BEBHgAAOiLAAwBARwR4AADoiAAPAAAdWXWAr6oHVNVLq+ojVfW1qrq9qnZW1eeq6iVVNXYfVXVMVV1cVTuq6raqurqqTq2qvXaxr5Or6gtVdcuwj8uq6pmrPQcAAOjFJGbgX5DkvUmOTvL3Sd6W5MNJHpHkfUn+uqpq4QZV9ewklyc5NslHkrwryT5J3prkgnE7qaqzk5yb5IHD/s5P8sgkH6uqV0zgPAAAYMPbewJtXJfkWUk+3lq7a35hVb0uyReSPD/J8zIK9amqAzIK4D9Nclxr7R+G5W9IckmSE6vqpNbaBQvaOibJaUmuT/L41toPh+VnJdme5Oyquqi1NjeB8wEAgA1r1TPwrbVLWmsfWxjeh+XfS/Ke4etxC1admOQXklwwH96H+j9J8vrh6+8t2s3Lh/LN8+F92GYuo9n7fZO8eHVnAgAAG99a38T6b0N554Jlxw/lJ8fUvzzJbUmOqap9l7nNJxbVAQCATWsSl9CMVVV7J/mt4evC4P3wobxu8TattTur6oYkRyY5NMm1VbV/kgcnuaW19t0xu/rqUB62zOPavsSqw5ezPQAATNNazsCfmdGNrBe31j61YPmWody5xHbzyw/cw/oAALBprckMfFW9KqObTr+c5EUr3Xwo2wq3W1b91tpRY3c6mpl/7Ar3CQAA62riM/BVdUqStyf5UpKntNZ2LKoyP2O+JeMdsKje7urvboYeAAA2jYkG+Ko6Nck5Sa7JKLx/b0y1rwzlva5ZH66bf0hGN71+PUlaa7cm+XaS+1fVA8e097ChvNc19QAAsNlMLMBX1R9m9CKmL2YU3m9couolQ3nCmHXHJrlfkitba3csc5unL6oDAACb1kQC/PASpjMzeqnSU1trN+2i+oVJbkpyUlU9bkEb+yV50/D13Yu2mX+e/BlVddCCbbYmOSXJHUk+sJpzAACAHqz6JtaqOjnJn2T0ZtUrkryqqhZXm2utnZskrbWbq+p3Mgryl1XVBUl2ZPQ214cPyz+0cOPW2pVV9ZYkr0lydVVdmGSfJC9McnCSV3oLKwAAs2AST6F5yFDuleTUJep8Nsm5819aax+tqicnOSPJ85Psl+RrGQX0d7TW7vVEmdbaaVV1dZJXJHlZkruSXJXkrNbaRRM4DwAA2PBWHeBba9uSbNuD7T6f5NdXuM15Sc5b6b4AAGCzWMsXOQEAABMmwAMAQEcEeAAA6IgADwAAHRHgAQCgIwI8AAB0RIAHAICOCPAAANARAR4AADoiwAMAQEcEeAAA6IgADwAAHRHgAQCgIwI8AAB0RIAHAICOCPAAANARAR4AADoiwAMAQEcEeAAA6IgADwAAHRHgAQCgIwI8AAB0RIAHAICOCPAAANARAR4AADoiwAMAQEcEeAAA6IgADwAAHRHgAQCgIwI8AAB0RIAHAICOCPAAANARAR4AADoiwAMAQEcEeAAA6IgADwAAHRHgAQCgIwI8AAB0RIAHAICOCPAAANARAR4AADoiwAMAQEcEeAAA6IgADwAAHRHgAQCgIwI8AAB0RIAHAICOCPAAANARAR4AADoiwAMAQEcEeAAA6IgADwAAHRHgAQCgIwI8AAB0RIAHAICOCPAAANARAR4AADoiwAMAQEcEeAAA6IgADwAAHRHgAQCgIwI8AAB0RIAHAICOCPAAANARAR4AADoiwAMAQEcEeAAA6IgADwAAHZlIgK+qE6vqnVV1RVXdXFWtqs5fou7WYf1Snwt2sZ+Tq+oLVXVLVe2sqsuq6pmTOAcAAOjB3hNq5/VJHp3kliTfSnL4Mrb5pyQfHbP8mnGVq+rsJKcN7b83yT5JTkrysap6ZWvtnJUfNgAA9GVSAf7VGQXrryV5cpJLl7HNF1tr25bTeFUdk1F4vz7J41trPxyWn5Vke5Kzq+qi1trcyg8dAAD6MZFLaFprl7bWvtpaa5Nob4yXD+Wb58P7sN+5JO9Ksm+SF6/RvgEAYMOY5k2sD6qq362q1w3lo3ZR9/ih/OSYdZ9YVAcAADatSV1Csyd+bfj8TFVdluTk1to3FyzbP8mDk9zSWvvumHa+OpSHLWenVbV9iVXLuW4fAACmahoz8Lcl+dMkRyU5aPjMXzd/XJLPDKF93pah3LlEe/PLD5z0gQIAwEaz7jPwrbUbk/zRosWXV9XTknwuydFJXprk7Sttepn7P2rc8mFm/rEr3CcAAKyrDfMip9banUneN3w9dsGq+Rn2LRlvdzP0AACwaWyYAD/4wVD+7BKa1tqtSb6d5P5V9cAx2zxsKK9b42MDAICp22gB/glD+fVFyy8ZyhPGbPP0RXUAAGDTWvcAX1VHV9U+Y5Yfn9ELoZLk/EWr3zOUZ1TVQQu22ZrklCR3JPnA5I8WAAA2loncxFpVz0nynOHrIUP5xKo6d/j1Ta2104df/1mSI4dHRn5rWPao3P0c9ze01q5c2H5r7cqqekuS1yS5uqouTLJPkhcmOTjJK72FFQCAWTCpp9A8JsnJi5YdOnyS5BtJ5gP8B5M8N8njM7r85eeSfD/JXyc5p7V2xbgdtNZOq6qrk7wiycuS3JXkqiRntdYumtB5AADAhjaRAN9a25Zk2zLrvj/J+/dwP+clOW9PtgUAgM1go93ECgAA7IIADwAAHRHgAQCgIwI8AAB0RIAHAICOCPAAANARAR4AADoiwAMAQEcEeAAA6IgADwAAHRHgAQCgIwI8AAB0RIAHAICOCPAAANARAR4AADoiwAMAQEcEeAAA6IgADwAAHRHgAQCgIwI8AAB0RIAHAICOCPAAANARAR4AADoiwAMAQEcEeAAA6IgADwAAHRHgAQCgIwI8AAB0RIAHAICOCPAAANARAR4AADoiwAMAQEcEeAAA6IgADwAAHRHgAQCgIwI8AAB0RIAHAICOCPAAANARAR4AADoiwAMAQEcEeAAA6IgADwAAHRHgAQCgIwI8AAB0RIAHAICOCPAAANARAR4AADoiwAMAQEcEeAAA6IgADwAAHRHgAQCgIwI8AAB0RIAHAICOCPAAANARAR4AADoiwAMAQEcEeAAA6IgADwAAHRHgAQCgIwI8AAB0RIAHAICOCPAAANARAR4AADoiwAMAQEcEeAAA6IgADwAAHRHgAQCgIwI8AAB0RIAHAICOTCTAV9WJVfXOqrqiqm6uqlZV5+9mm2Oq6uKq2lFVt1XV1VV1alXttYttTq6qL1TVLVW1s6ouq6pnTuIcAACgB5OagX99klckeUySb++uclU9O8nlSY5N8pEk70qyT5K3JrlgiW3OTnJukgcmeW+S85M8MsnHquoVqz0BAADowaQC/KuTHJbkgCS/t6uKVXVARgH8p0mOa629pLX2PzIK//8nyYlVddKibY5JclqS65M8qrX26tbaKUmOSrIjydlVtXVC5wIAABvWRAJ8a+3S1tpXW2ttGdVPTPILSS5orf3DgjZ+ktFMfnLvHwJePpRvbq39cME2cxnN3u+b5MV7ePgAANCNadzEevxQfnLMusuT3JbkmKrad5nbfGJRHQAA2LT2nsI+Hz6U1y1e0Vq7s6puSHJkkkOTXFtV+yd5cJJbWmvfHdPeV4fysOXsvKq2L7Hq8OVsDwAA0zSNGfgtQ7lzifXzyw/cw/oAALBpTWMGfndqKJdzPf1Cy6rfWjtq7E5HM/OPXeE+AQBgXU1jBn5+xnzLEusPWFRvd/V3N0MPAACbxjQC/FeG8l7XrFfV3kkekuTOJF9PktbarRk9W/7+VfXAMe09bCjvdU09AABsNtMI8JcM5Qlj1h2b5H5Jrmyt3bHMbZ6+qA4AAGxa0wjwFya5KclJVfW4+YVVtV+SNw1f371om/cM5RlVddCCbbYmOSXJHUk+sFYHDAAAG8VEbmKtquckec7w9ZChfGJVnTv8+qbW2ulJ0lq7uap+J6Mgf1lVXZDR21SfldEjJi9M8qGF7bfWrqyqtyR5TZKrq+rCJPskeWGSg5O8cnipEwAAbGqTegrNY5KcvGjZocMnSb6R5PT5Fa21j1bVk5OckeT5SfZL8rWMAvo7xr3RtbV2WlVdneQVSV6W5K4kVyU5q7V20YTOAwAANrSJBPjW2rYk21a4zeeT/PoKtzkvyXkr2QYAADaTaVwDDwAA7CEBHgAAOiLAAwBARwR4AADoiAAPAAAdEeABAKAjAjwAAHREgAcAgI4I8AAA0BEBHgAAOiLAAwBARwR4AADoiAAPAAAdEeABAKAjAjwAAHREgAcAgI4I8AAA0BEBHgAAOiLAAwBARwR4AADoiAAPAAAdEeABAKAjAjwAAHREgAcAgI4I8AAA0BEBHgAAOiLAAwBARwR4AADoiAAPAAAdEeABAKAjAjwAAHREgAcAgI4I8AAA0BEBHgAAOiLAAwBARwR4AADoiAAPAAAdEeABAKAjAjwAAHREgAcAgI4I8AAA0BEBHgAAOiLAAwBARwR4AADoiAAPAAAdEeABAKAjAjwAAHREgAcAgI4I8AAA0BEBHgAAOiLAAwBARwR4AADoiAAPAAAdEeABAKAjAjwAAHREgAcAgI4I8AAA0BEBHgAAOiLAAwBARwR4AADoiAAPAAAdEeABAKAje0/7AACYXVtf+/FpHwJTNnfmM6Z9CNAdM/AAANARM/Aw48yAzjaznwD9MQMPAAAdEeABAKAjAjwAAHRkagG+quaqqi3x+d4S2xxTVRdX1Y6quq2qrq6qU6tqr/U+fgAAmIZp38S6M8nbxiy/ZfGCqnp2kg8n+UmSDyXZkeQ3krw1yZOSvGDNjhIAADaIaQf4H7XWtu2uUlUdkOS9SX6a5LjW2j8My9+Q5JIkJ1bVSa21C9byYAEAYNp6uQb+xCS/kOSC+fCeJK21nyR5/fD196ZxYAAAsJ6mPQO/b1X9ZpL/kOTWJFcnuby19tNF9Y4fyk+OaePyJLclOaaq9m2t3bFmRwsAAFM27QB/SJIPLlp2Q1W9uLX22QXLHj6U1y1uoLV2Z1XdkOTIJIcmuXZXO6yq7UusOnx5hwwAANMzzUtoPpDkqRmF+P2TPDLJXyTZmuQTVfXoBXW3DOXOJdqaX37gxI8SAAA2kKnNwLfW3rho0TVJXl5VtyQ5Lcm2JM9dZnM13+wy9nvU2AZGM/OPXeb+AABgKjbiTazvGcpjFyybn2HfkvEOWFQPAAA2pY0Y4G8cyv0XLPvKUB62uHJV7Z3kIUnuTPL1tT00AACYro0Y4J84lAvD+CVDecKY+scmuV+SKz2BBgCAzW4qAb6qjqyqg8cs/5Uk5wxfz1+w6sIkNyU5qaoet6D+fkneNHx99xodLgAAbBjTuon1BUleW1WXJrkhyY+TPDTJM5Lsl+TiJGfPV26t3VxVv5NRkL+sqi5IsiPJszJ6xOSFST60rmcAAABTMK0Af2lGwfs/ZXTJzP5JfpTkcxk9F/6DrbV7PFGmtfbRqnpykjOSPD+joP+1JK9J8o7F9QEAYDOaSoAfXtL02d1WvPd2n0/y65M/IgAA6MNGvIkVAABYggAPAAAdEeABAKAjAjwAAHREgAcAgI4I8AAA0BEBHgAAOiLAAwBARwR4AADoiAAPAAAdEeABAKAjAjwAAHREgAcAgI4I8AAA0BEBHgAAOiLAAwBARwR4AADoiAAPAAAdEeABAKAjAjwAAHREgAcAgI4I8AAA0BEBHgAAOiLAAwBARwR4AADoiAAPAAAd2XvaBwAAMC1bX/vxaR8CUzR35jOmfQh7xAw8AAB0RIAHAICOCPAAANARAR4AADoiwAMAQEcEeAAA6IgADwAAHRHgAQCgIwI8AAB0RIAHAICOCPAAANARAR4AADoiwAMAQEcEeAAA6IgADwAAHRHgAQCgIwI8AAB0RIAHAICOCPAAANARAR4AADoiwAMAQEcEeAAA6IgADwAAHRHgAQCgIwI8AAB0RIAHAICOCPAAANARAR4AADoiwAMAQEcEeAAA6IgADwAAHRHgAQCgIwI8AAB0RIAHAICOCPAAANARAR4AADoiwAMAQEcEeAAA6IgADwAAHRHgAQCgIwI8AAB0RIAHAICOdBXgq+qXq+ovq+o7VXVHVc1V1duq6qBpHxsAAKyHvad9AMtVVQ9NcmWSX0zyN0m+nORXk/xBkhOq6kmttX+Z4iECAMCa62kG/s8zCu+vaq09p7X22tba8UnemuThSd481aMDAIB10EWAr6pDkzwtyVySdy1a/cdJbk3yoqraf50PDQAA1lUXAT7J8UP56dbaXQtXtNZ+nOTzSe6X5AnrfWAAALCeqrU27WPYrao6K8npSU5vrf3PMevPSXJKkt9vrb17N21tX2LVo+973/vudcQRR6z6eFfqmm/vXPd9snE84sFbprp/42+2GX9MmzHINE1j/F177bW5/fbbd7TWHrCnbfRyE+t87y71p2x++YGr2MdPb7/99p1XXXXV3Aq3O3wov7yKfc+yme+/q76/qs1nvv9Waeb7z/ibupnvQ2Nwqma+/6Y0/rYmuXk1O+4lwO9ODeVu/zuhtXbURHc8zOhPut1Zof9WR/+tjv5bHf23evpwdfTf6ui/1Zlm//VyDfz8DPtS/89xwKJ6AACwKfUS4L8ylIctsf5hQ3ndOhwLAABMTS8B/tKhfFpV3eOYq+rnkzwpye1J/m69DwwAANZTFwG+tXZ9kk9ndNH/KYtWvzHJ/kn+qrV26zofGgAArKuebmL9/SRXJnlHVT01ybVJjk7ylIwunTljiscGAADroovnwM+rqn+f5E+SnJDkAUm+m+SjSd7YWtsxxUMDAIB10VWABwCAWdfFNfAAAMCIAA8AAB0R4AEAoCMCPAAAdESABwCAjgjwAADQEQF+harqmKq6uKp2VNVtVXV1VZ1aVXutoI2tVdV28blgLc9hrVXVL1fVX1bVd6rqjqqaq6q3VdVB02inN5M472GbpcbX99by+Kepqk6sqndW1RVVdfNwvufvYVszN/4m1X+zOP6q6gFV9dKq+khVfa2qbq+qnVX1uap6SVWt6N/bWRt/k+y/WRx/SVJVf1ZVn6mqfx76b0dV/WNV/XFVPWCFbc3U+Js3qT5cjzHoOfArUFXPTvLhJD9J8qEkO5L8RpKHJ7mwtfaCZbazNckNSf4poxdRLXZNa+3CCRzyuquqh2b0xtxfTPI3Sb6c5FczemPuV5I8qbX2L+vVTm8m2H9zSQ5M8rYxq29prZ09mSPeWKrqi0keneSWJN9KcniS/9Va+80VtjOr4++LmUz/zWXGxl9VvTzJuzN6weClSb6Z5JeSPC/Jloz+7XhBW8Y/urM4/ibcf3OZsfGXJFX1r0muSvKlJDcm2T/JE5I8Lsl3kjyhtfbPy2hn5sbfvAn24VzWegy21nyW8UlywPCbeUeSxy1Yvl9GA70lOWmZbW0d6p877fNag3761HBur1y0/C3D8vesZzu9fSbYf3NJ5qZ9PlPov6ckeViSSnLc0GfnT+v3obfPBPtv5sZfkuMzmtC5z6Llh2QURluS5y+zrZkbfxPuv5kbf8N577fE8jcP/ffny2xn5sbfGvThmo/BqXdWL58k/334zTtvzLrjh3WfXWZbmzLAJzl0OK8bxvwl/PMZzerdmmT/9Wint88kz3tW/wFb1Ad7FEBndfxNqv+GbWd+/C3qj9cNffnOZdQ1/lbRf0N94++e/fHoof/+dhl1jb9V9uFQf83HoGvgl+/4ofzkmHWXJ7ktyTFVte8K2nxQVf1uVb1uKB+16qOcrvk++nRr7a6FK1prP07y+ST3y+i/o9ajnd5M+rz3rarfHMbXH1TVU2oF92rMsFkdf5Nm/N3t34byzmXUNf7ubSX9N8/4u9tvDOXVy6hr/I23kj6ct6ZjcO9JNTQDHj6U1y1e0Vq7s6puSHJkRj+9XrvMNn9t+PxMVV2W5OTW2jf3/FCnZsk+Gnw1ydOSHJbkM+vQTm8mfd6HJPngomU3VNWLW2uf3bNDnAmzOv4mzfhLUlV7J/mt4eu4CaDFjL8F9qD/5s3s+Kuq05PcP6N7Bx6X5D9nFDzPXMbmxl9W3Yfz1nQMmoFfvi1DuXOJ9fPLD1xGW7cl+dMkRyU5aPg8OaMbd45L8pmq2n9PD3SKJtVHk+zrnkzyvD+Q5KkZ/QWyf5JHJvmLjC7f+kRVPXqPj3Lzm9XxN0nG393OTPKIJBe31j61jPrG3z2ttP8S4+/0JH+c5NSMgucnkzyttfaDZWxr/I2spg+TdRiDMxXgd/NYn3GflTw+rYZyt3fIt9ZubK39UWvtqtbaj4bP5Rn9VPv3Sf5jkpeu/Aw3vGX30Tq105uVjLE3ttYuaa19v7V2W2vtmtbayzO6Cem+Sbat4XFudrM6/pbN+BupqlclOS2jp3i8aFLNDuWmH3972n+zPv5aa4e01iqj8Pi8jK4M+MeqeuwEmp+J8bfaPlyPMThTAT7J9Rk9Amm5n+8s2Hb+p84tGe+ARfVWrLV2Z5L3DV+P3dN2pmhSfbTmfb1Brcd5v2coexxf62VWx996mJnxV1WnJHl7Ro+je0prbccyNzX+sqr+25WZGX9JMoTHj2Q0OfiAJH+1jM2MvwX2sA93ZWJjcKaugW+tPXUVm38lo+ugDkuyfeGK4Rq9h2R0g83XV7GPJJn/75keL6H5ylAetsT6hw3lUtfWTbqd3qzHed84lD2Or/Uyq+NvPczE+KuqU5O8Nck1SZ7aWrtx11vcw8yPv1X2367MxPhbrLX2jar6UpLHVNW/a63dtIvqMz/+xllhH+7KxMbgrM3Ar8YlQ3nCmHXHZnRX9pWttTtWuZ/5O7tX+4PANFw6lE+rRW/Nq6qfT/KkJLcn+bt1aqc363HeTxzKHsfXepnV8bceNv34q6o/zCh8fjGjmeOVhs+ZHn8T6L9d2fTjbxceNJQ/3U29mR5/u7HcPtyViY1BAX75LkxyU5KTqupx8wurar8kbxq+vnvhBlW1paoOr6oHLlp+dFXts3gHVXV8klcPX/fo9e/T1Fq7PsmnM7pJ45RFq9+Y0U+cf9VauzVJqurnhv556Gra2Swm1X9VdWRVHby4/ar6lSTnDF+7G1+TZvytjvF3b1X1hoxuutye0czxkrN0xt+9TaL/ZnX8DX1xyJjl96mqN2f0VtUrW2s/HJYbf4tMqg/XawzW8MB5lqGqnpNRkP9JkguS7EjyrIweu3Rhkv/WFnRoVf12Rncin9da++0Fyy/L6JGTl2X0uvIkeVTufv7qG1pr8z8UdKXu/Qrma5McndEbHq9LckwbXsFcVVszelnEN1prW/e0nc1kEv1XVduSvDajmZQbkvw4yUOTPCOjNwdfnOS5rbV/XY9zWk/Dn9HnDF8PSfJfM5rpuGJYdlNr7fSh7tYYf/cwif6b1fFXVScnOTej2bl3Zvw1wnOttXOH+ltj/P3MpPpvhsffqUnOyui9NNcn+Zckv5TRE+4OTfK9jH4o+tJQf2uMv3uYVB+u2xhcztuefO7xdq0nDZ3/w4z+G+n/ZTRrvteYur+dMW9cTfKSJBdl9KauW5LckdGroj+U5L9M+xwn0Ef/PqMfXL6b5F+TfCOjm5EOXlRv69A/c6tpZ7N9Vtt/Gf1l878zenLDjzJ6CcoPkvxtRs9Trmmf4xr23bahT5b6zC2oa/ytQf/N6vhbRt+1JJcZf2vbfzM8/h6R5F0ZXXp0U0b35O1M8n+HvvXv7zr14XqNQTPwAADQEdfAAwBARwR4AADoiAAPAAAdEeABAKAjAjwAAHREgAcAgI4I8AAA0BEBHgAAOiLAAwBARwR4AADoiAAPAAAdEeABAKAjAjwAAHREgAcAgI4I8AAA0BEBHgAAOiLAAwBAR/4/9rgJtUTlGc0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 376
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# label encode the target variable\n",
    "y = LabelEncoder().fit_transform(train_y)\n",
    "# summarize distribution\n",
    "counter = Counter(y)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y) * 100\n",
    "    print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# plot the distribution\n",
    "pyplot.bar(counter.keys(), counter.values())\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(390, 10, 50, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "orig_shape = train_X.shape\n",
    "print(orig_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(390, 75000)\n"
     ]
    }
   ],
   "source": [
    "train2D_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[1] * train_X.shape[2] * train_X.shape[3] * train_X.shape[4]))\n",
    "print(train2D_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, n=248 (25.000%)\n",
      "Class=1, n=248 (25.000%)\n",
      "Class=2, n=248 (25.000%)\n",
      "Class=3, n=248 (25.000%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 376
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "# label encode the target variable\n",
    "y = LabelEncoder().fit_transform(train_y)\n",
    "# transform the dataset\n",
    "oversample = SMOTE()\n",
    "new_train_X, new_train_y = oversample.fit_resample(train2D_X, y)\n",
    "# summarize distribution\n",
    "counter = Counter(new_train_y)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(new_train_y) * 100\n",
    "    print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# plot the distribution\n",
    "pyplot.bar(counter.keys(), counter.values())\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_y = new_train_y.astype(np.float)\n",
    "for i in range(len(new_train_y)):\n",
    "    if new_train_y[i] == 1:\n",
    "        new_train_y[i] = 0.05\n",
    "    if new_train_y[i] == 2:\n",
    "        new_train_y[i] = 0.25\n",
    "    if new_train_y[i] == 3:\n",
    "        new_train_y[i] = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(992, 10, 50, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "new_shape = (new_train_X.shape[0], train_X.shape[1], train_X.shape[2], train_X.shape[3], train_X.shape[4])\n",
    "new_train_X = np.reshape(new_train_X, new_shape)\n",
    "print(new_train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1135,
     "status": "ok",
     "timestamp": 1611704661548,
     "user": {
      "displayName": "Jay Wang",
      "photoUrl": "",
      "userId": "08806282010227278078"
     },
     "user_tz": -780
    },
    "id": "UbbRaZ3QqKdE",
    "outputId": "e9f226de-bde7-4688-d5e0-cd099053637f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 50, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "training_image_size = ( train_X.shape[1], train_X.shape[2], train_X.shape[3], train_X.shape[4] )\n",
    "print( training_image_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 894,
     "status": "ok",
     "timestamp": 1611704663392,
     "user": {
      "displayName": "Jay Wang",
      "photoUrl": "",
      "userId": "08806282010227278078"
     },
     "user_tz": -780
    },
    "id": "GZ5wQ4lfU7lz",
    "outputId": "4961e0fe-8169-4f38-80fa-b1c631d25b94"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f90d85a2fd0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 249,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_X[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "executionInfo": {
     "elapsed": 868,
     "status": "ok",
     "timestamp": 1611704666976,
     "user": {
      "displayName": "Jay Wang",
      "photoUrl": "",
      "userId": "08806282010227278078"
     },
     "user_tz": -780
    },
    "id": "k3bfZaUnCEXI"
   },
   "outputs": [],
   "source": [
    "#from sklearn.utils import shuffle\n",
    "new_train_X, new_train_y = shuffle(new_train_X, new_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 822,
     "status": "ok",
     "timestamp": 1611704668656,
     "user": {
      "displayName": "Jay Wang",
      "photoUrl": "",
      "userId": "08806282010227278078"
     },
     "user_tz": -780
    },
    "id": "rA9wqjvyDM-M",
    "outputId": "df5edc4f-ac7c-4e12-e7a0-8f765b5c1b08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4 , 0.05, 0.05, 0.  , 0.4 , 0.05, 0.  , 0.25, 0.4 , 0.  , 0.25,\n",
       "       0.25, 0.05, 0.4 , 0.4 , 0.  , 0.05, 0.  , 0.4 , 0.25, 0.25, 0.05,\n",
       "       0.  , 0.05, 0.05, 0.4 , 0.4 , 0.05, 0.  , 0.25, 0.  , 0.4 , 0.4 ,\n",
       "       0.4 , 0.05, 0.05, 0.  , 0.  , 0.05, 0.05, 0.  , 0.4 , 0.25, 0.4 ,\n",
       "       0.25, 0.25, 0.05, 0.  , 0.  , 0.25, 0.4 , 0.4 , 0.4 , 0.  , 0.4 ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.05, 0.05, 0.05, 0.05, 0.25, 0.25, 0.4 ,\n",
       "       0.4 , 0.4 , 0.25, 0.4 , 0.  , 0.25, 0.4 , 0.05, 0.4 , 0.4 , 0.25,\n",
       "       0.25, 0.05, 0.  , 0.25, 0.05, 0.05, 0.  , 0.4 , 0.05, 0.4 , 0.05,\n",
       "       0.  , 0.05, 0.  , 0.4 , 0.  , 0.4 , 0.  , 0.  , 0.  , 0.4 , 0.4 ,\n",
       "       0.4 , 0.05, 0.25, 0.05, 0.05, 0.  , 0.05, 0.05, 0.05, 0.4 , 0.25,\n",
       "       0.4 , 0.05, 0.05, 0.  , 0.25, 0.  , 0.25, 0.  , 0.05, 0.  , 0.05,\n",
       "       0.4 , 0.25, 0.4 , 0.25, 0.  , 0.05, 0.  , 0.4 , 0.  , 0.25, 0.  ,\n",
       "       0.25, 0.05, 0.  , 0.25, 0.4 , 0.  , 0.4 , 0.25, 0.05, 0.  , 0.  ,\n",
       "       0.25, 0.05, 0.4 , 0.4 , 0.05, 0.25, 0.05, 0.05, 0.05, 0.  , 0.05,\n",
       "       0.05, 0.4 , 0.  , 0.25, 0.25, 0.25, 0.  , 0.  , 0.4 , 0.25, 0.25,\n",
       "       0.05, 0.4 , 0.  , 0.25, 0.05, 0.  , 0.  , 0.25, 0.  , 0.4 , 0.05,\n",
       "       0.25, 0.4 , 0.4 , 0.  , 0.25, 0.  , 0.4 , 0.25, 0.25, 0.25, 0.  ,\n",
       "       0.4 , 0.25, 0.25, 0.  , 0.25, 0.  , 0.05, 0.25, 0.25, 0.05, 0.  ,\n",
       "       0.05, 0.4 , 0.25, 0.05, 0.05, 0.05, 0.05, 0.25, 0.  , 0.  , 0.25,\n",
       "       0.25, 0.25, 0.25, 0.4 , 0.05, 0.  , 0.4 , 0.05, 0.  , 0.  , 0.05,\n",
       "       0.4 , 0.25, 0.4 , 0.4 , 0.  , 0.  , 0.05, 0.05, 0.4 , 0.4 , 0.4 ,\n",
       "       0.4 , 0.25, 0.25, 0.25, 0.25, 0.  , 0.4 , 0.4 , 0.4 , 0.05, 0.25,\n",
       "       0.  , 0.25, 0.25, 0.4 , 0.05, 0.  , 0.05, 0.25, 0.25, 0.05, 0.  ,\n",
       "       0.4 , 0.  , 0.4 , 0.  , 0.05, 0.4 , 0.05, 0.  , 0.  , 0.  , 0.4 ,\n",
       "       0.05, 0.4 , 0.05, 0.4 , 0.4 , 0.05, 0.05, 0.25, 0.4 , 0.  , 0.25,\n",
       "       0.25, 0.  , 0.25, 0.25, 0.4 , 0.4 , 0.05, 0.4 , 0.4 , 0.25, 0.05,\n",
       "       0.05, 0.25, 0.4 , 0.4 , 0.05, 0.05, 0.4 , 0.05, 0.4 , 0.25, 0.05,\n",
       "       0.25, 0.  , 0.25, 0.4 , 0.  , 0.  , 0.25, 0.25, 0.25, 0.05, 0.25,\n",
       "       0.25, 0.4 , 0.25, 0.  , 0.4 , 0.4 , 0.05, 0.05, 0.05, 0.05, 0.  ,\n",
       "       0.4 , 0.25, 0.25, 0.25, 0.05, 0.05, 0.  , 0.05, 0.05, 0.  , 0.25,\n",
       "       0.4 , 0.  , 0.25, 0.  , 0.  , 0.4 , 0.4 , 0.  , 0.4 , 0.05, 0.25,\n",
       "       0.05, 0.25, 0.05, 0.25, 0.  , 0.25, 0.25, 0.4 , 0.05, 0.25, 0.25,\n",
       "       0.25, 0.25, 0.  , 0.4 , 0.4 , 0.  , 0.05, 0.25, 0.4 , 0.25, 0.25,\n",
       "       0.  , 0.05, 0.  , 0.05, 0.25, 0.25, 0.  , 0.25, 0.05, 0.05, 0.25,\n",
       "       0.4 , 0.4 , 0.25, 0.4 , 0.05, 0.  , 0.25, 0.  , 0.4 , 0.  , 0.  ,\n",
       "       0.05, 0.4 , 0.25, 0.4 , 0.  , 0.25, 0.  , 0.25, 0.05, 0.4 , 0.4 ,\n",
       "       0.25, 0.4 , 0.  , 0.25, 0.4 , 0.05, 0.05, 0.  , 0.4 , 0.05, 0.05,\n",
       "       0.  , 0.25, 0.25, 0.4 , 0.4 , 0.  , 0.4 , 0.05, 0.25, 0.05, 0.4 ,\n",
       "       0.25, 0.  , 0.4 , 0.25, 0.25, 0.25, 0.  , 0.05, 0.05, 0.  , 0.05,\n",
       "       0.  , 0.05, 0.  , 0.4 , 0.  , 0.4 , 0.4 , 0.25, 0.4 , 0.25, 0.4 ,\n",
       "       0.05, 0.  , 0.  , 0.05, 0.  , 0.4 , 0.05, 0.4 , 0.  , 0.25, 0.  ,\n",
       "       0.25, 0.4 , 0.05, 0.05, 0.05, 0.  , 0.25, 0.4 , 0.05, 0.25, 0.25,\n",
       "       0.25, 0.25, 0.  , 0.  , 0.05, 0.4 , 0.  , 0.25, 0.4 , 0.4 , 0.4 ,\n",
       "       0.25, 0.25, 0.05, 0.05, 0.25, 0.25, 0.4 , 0.25, 0.05, 0.  , 0.  ,\n",
       "       0.05, 0.4 , 0.05, 0.25, 0.  , 0.  , 0.4 , 0.4 , 0.  , 0.4 , 0.  ,\n",
       "       0.05, 0.4 , 0.25, 0.4 , 0.4 , 0.05, 0.05, 0.25, 0.4 , 0.05, 0.05,\n",
       "       0.4 , 0.05, 0.  , 0.  , 0.05, 0.4 , 0.4 , 0.  , 0.05, 0.05, 0.25,\n",
       "       0.  , 0.  , 0.25, 0.05, 0.25, 0.  , 0.25, 0.4 , 0.05, 0.  , 0.25,\n",
       "       0.05, 0.4 , 0.25, 0.25, 0.  , 0.  , 0.4 , 0.  , 0.25, 0.4 , 0.25,\n",
       "       0.  , 0.25, 0.  , 0.25, 0.25, 0.05, 0.  , 0.25, 0.4 , 0.4 , 0.05,\n",
       "       0.05, 0.  , 0.05, 0.05, 0.4 , 0.25, 0.  , 0.4 , 0.05, 0.4 , 0.4 ,\n",
       "       0.05, 0.4 , 0.  , 0.05, 0.25, 0.  , 0.05, 0.05, 0.4 , 0.25, 0.  ,\n",
       "       0.4 , 0.4 , 0.4 , 0.  , 0.05, 0.25, 0.25, 0.4 , 0.05, 0.25, 0.25,\n",
       "       0.4 , 0.  , 0.  , 0.05, 0.05, 0.05, 0.25, 0.  , 0.  , 0.05, 0.25,\n",
       "       0.25, 0.05, 0.4 , 0.05, 0.  , 0.25, 0.4 , 0.4 , 0.  , 0.4 , 0.05,\n",
       "       0.4 , 0.05, 0.4 , 0.  , 0.25, 0.  , 0.4 , 0.25, 0.  , 0.05, 0.25,\n",
       "       0.05, 0.05, 0.4 , 0.4 , 0.25, 0.  , 0.05, 0.05, 0.05, 0.25, 0.25,\n",
       "       0.4 , 0.  , 0.25, 0.  , 0.05, 0.25, 0.4 , 0.25, 0.25, 0.05, 0.  ,\n",
       "       0.4 , 0.05, 0.  , 0.4 , 0.25, 0.05, 0.4 , 0.05, 0.05, 0.  , 0.25,\n",
       "       0.4 , 0.4 , 0.  , 0.4 , 0.05, 0.  , 0.25, 0.25, 0.05, 0.  , 0.05,\n",
       "       0.4 , 0.  , 0.25, 0.05, 0.  , 0.4 , 0.  , 0.4 , 0.  , 0.  , 0.  ,\n",
       "       0.25, 0.05, 0.25, 0.4 , 0.05, 0.25, 0.25, 0.  , 0.  , 0.4 , 0.4 ,\n",
       "       0.05, 0.05, 0.4 , 0.  , 0.25, 0.4 , 0.05, 0.4 , 0.25, 0.  , 0.  ,\n",
       "       0.4 , 0.4 , 0.25, 0.05, 0.25, 0.05, 0.05, 0.25, 0.  , 0.4 , 0.  ,\n",
       "       0.25, 0.  , 0.05, 0.  , 0.25, 0.4 , 0.05, 0.25, 0.25, 0.  , 0.  ,\n",
       "       0.4 , 0.4 , 0.05, 0.  , 0.4 , 0.4 , 0.  , 0.  , 0.4 , 0.  , 0.25,\n",
       "       0.05, 0.05, 0.25, 0.  , 0.  , 0.  , 0.4 , 0.4 , 0.  , 0.25, 0.25,\n",
       "       0.25, 0.05, 0.25, 0.4 , 0.4 , 0.05, 0.  , 0.05, 0.05, 0.4 , 0.4 ,\n",
       "       0.05, 0.  , 0.4 , 0.05, 0.25, 0.  , 0.05, 0.05, 0.4 , 0.4 , 0.25,\n",
       "       0.  , 0.4 , 0.4 , 0.  , 0.  , 0.25, 0.  , 0.4 , 0.  , 0.  , 0.05,\n",
       "       0.  , 0.4 , 0.4 , 0.25, 0.25, 0.05, 0.05, 0.05, 0.4 , 0.  , 0.25,\n",
       "       0.05, 0.05, 0.05, 0.25, 0.  , 0.25, 0.  , 0.05, 0.25, 0.25, 0.4 ,\n",
       "       0.05, 0.05, 0.  , 0.  , 0.05, 0.  , 0.4 , 0.4 , 0.4 , 0.  , 0.4 ,\n",
       "       0.05, 0.  , 0.25, 0.05, 0.25, 0.25, 0.25, 0.  , 0.4 , 0.4 , 0.  ,\n",
       "       0.  , 0.  , 0.25, 0.  , 0.4 , 0.25, 0.4 , 0.05, 0.  , 0.  , 0.  ,\n",
       "       0.4 , 0.4 , 0.4 , 0.25, 0.05, 0.25, 0.25, 0.  , 0.25, 0.05, 0.25,\n",
       "       0.25, 0.05, 0.05, 0.05, 0.  , 0.05, 0.25, 0.4 , 0.4 , 0.4 , 0.05,\n",
       "       0.05, 0.  , 0.  , 0.4 , 0.25, 0.  , 0.4 , 0.05, 0.05, 0.4 , 0.25,\n",
       "       0.4 , 0.05, 0.4 , 0.05, 0.05, 0.05, 0.4 , 0.4 , 0.  , 0.4 , 0.25,\n",
       "       0.  , 0.05, 0.05, 0.25, 0.05, 0.  , 0.  , 0.  , 0.05, 0.25, 0.25,\n",
       "       0.4 , 0.4 , 0.05, 0.25, 0.4 , 0.  , 0.05, 0.  , 0.  , 0.4 , 0.  ,\n",
       "       0.  , 0.25, 0.05, 0.  , 0.  , 0.05, 0.  , 0.4 , 0.  , 0.  , 0.05,\n",
       "       0.  , 0.  , 0.4 , 0.25, 0.4 , 0.05, 0.25, 0.05, 0.25, 0.  , 0.  ,\n",
       "       0.4 , 0.25, 0.4 , 0.05, 0.25, 0.25, 0.05, 0.25, 0.05, 0.  , 0.05,\n",
       "       0.25, 0.4 , 0.05, 0.  , 0.05, 0.4 , 0.05, 0.05, 0.05, 0.  , 0.25,\n",
       "       0.4 , 0.05, 0.4 , 0.05, 0.4 , 0.4 , 0.  , 0.4 , 0.4 , 0.25, 0.4 ,\n",
       "       0.25, 0.25, 0.  , 0.  , 0.05, 0.  , 0.05, 0.25, 0.25, 0.25, 0.4 ,\n",
       "       0.25, 0.  , 0.25, 0.25, 0.4 , 0.4 , 0.  , 0.  , 0.25, 0.  , 0.05,\n",
       "       0.05, 0.05, 0.4 , 0.05, 0.  , 0.25, 0.25, 0.  , 0.4 , 0.4 , 0.  ,\n",
       "       0.25, 0.4 , 0.25, 0.05, 0.  , 0.4 , 0.25, 0.25, 0.25, 0.05, 0.25,\n",
       "       0.25, 0.  ])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuronsLevel = 32\n",
    "neuronsLevel*= 2\n",
    "neuronsLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2027,
     "status": "ok",
     "timestamp": 1611704673576,
     "user": {
      "displayName": "Jay Wang",
      "photoUrl": "",
      "userId": "08806282010227278078"
     },
     "user_tz": -780
    },
    "id": "PoOg1D8RUJ50",
    "outputId": "3ef6ce1d-b709-415b-faa1-fc04ddedc31e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "base (ConvLSTM2D)            (None, 10, 50, 50, 32)    363008    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 10, 25, 25, 32)    0         \n",
      "_________________________________________________________________\n",
      "myThing0 (ConvLSTM2D)        (None, 10, 25, 25, 64)    1990912   \n",
      "_________________________________________________________________\n",
      "myThing1 (ConvLSTM2D)        (None, 10, 25, 25, 128)   7963136   \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 10, 12, 12, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, 12, 12, 256)       31851520  \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 6, 256)        0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 12, 6, 320)        82240     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 12, 6, 320)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 6, 320)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 23040)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                1474624   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 43,725,505\n",
      "Trainable params: 43,725,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_convnet( neurons=32, kernels=4, layers=2, shrink=2):\n",
    "  model = Sequential()\n",
    "  neurons = int( neurons )\n",
    "  kernels = int( kernels )\n",
    "  layers = int( layers )\n",
    "  fred = int( kernels *2 +1 )\n",
    "  neuronsLevel = neurons\n",
    "  model.add(ConvLSTM2D( neuronsLevel, (fred, fred), name='base',activation='relu', padding='same', return_sequences=True, input_shape = training_image_size, kernel_initializer='glorot_uniform'))\n",
    "  model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "  for i in range( layers ):\n",
    "    neuronsLevel *= 2\n",
    "    model.add(ConvLSTM2D( int(neuronsLevel), (fred, fred), name=f'myThing{i}', activation='relu', padding='same', return_sequences=True))\n",
    "  model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "  #for l in range( layers ):\n",
    "    #model.add(ConvLSTM2D(neurons *32, (fred, fred), activation='relu', padding='same', return_sequences=True))\n",
    "  #model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "  neuronsLevel *= shrink\n",
    "  model.add(ConvLSTM2D(int(neuronsLevel), (fred, fred), activation='relu', padding='same', return_sequences=False))\n",
    "  model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "  model.add(Dense(320))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(0.1))\n",
    "\n",
    "\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(64, activation='relu'))\n",
    "  model.add(Dense(1, activation='relu'))\n",
    "\n",
    "\n",
    "  #out_shape = model.output_shape\n",
    "  #SequenceLength = train_X.shape[1]\n",
    "  #model.add(Reshape((SequenceLength, out_shape[1])))\n",
    "  #model.add(LSTM(64, return_sequences=False))\n",
    "  #model.add(Dropout(0.5))\n",
    "  #model.add(Dense(1, activation='relu'))\n",
    "  model.compile(loss='mse', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "  \n",
    " \n",
    "  # model structure summary\n",
    "  return model\n",
    "\n",
    "model = build_convnet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 847,
     "status": "ok",
     "timestamp": 1611704678657,
     "user": {
      "displayName": "Jay Wang",
      "photoUrl": "",
      "userId": "08806282010227278078"
     },
     "user_tz": -780
    },
    "id": "_ozvbVrVQjTV",
    "outputId": "e77b3fb9-22a5-400a-a9aa-282fbdc81c3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(992, 10, 50, 50, 3)\n",
      "(992,)\n",
      "(45, 10, 50, 50, 3)\n",
      "(45,)\n"
     ]
    }
   ],
   "source": [
    "print(new_train_X.shape)\n",
    "print(new_train_y.shape)\n",
    "print(test_X.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 306620,
     "status": "ok",
     "timestamp": 1611694452607,
     "user": {
      "displayName": "Jay Wang",
      "photoUrl": "",
      "userId": "08806282010227278078"
     },
     "user_tz": -780
    },
    "id": "jkU0iIAsUKAZ",
    "outputId": "7b4f283d-a861-445d-dc23-a206987296bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "223/223 [==============================] - 5934s 27s/step - loss: 0.0566 - accuracy: 0.2482 - val_loss: 0.0539 - val_accuracy: 0.2500\n",
      "Epoch 2/100\n",
      "223/223 [==============================] - 5907s 26s/step - loss: 0.0437 - accuracy: 0.2482 - val_loss: 0.0242 - val_accuracy: 0.2500\n",
      "Epoch 3/100\n",
      "223/223 [==============================] - 5353s 24s/step - loss: 0.0264 - accuracy: 0.2482 - val_loss: 0.0242 - val_accuracy: 0.2500\n",
      "Epoch 4/100\n",
      "223/223 [==============================] - 5366s 24s/step - loss: 0.0264 - accuracy: 0.2482 - val_loss: 0.0242 - val_accuracy: 0.2500\n",
      "Epoch 5/100\n",
      "223/223 [==============================] - 5631s 25s/step - loss: 0.0264 - accuracy: 0.2482 - val_loss: 0.0242 - val_accuracy: 0.2500\n",
      "Epoch 6/100\n",
      "223/223 [==============================] - 5343s 24s/step - loss: 0.0264 - accuracy: 0.2482 - val_loss: 0.0242 - val_accuracy: 0.2500\n",
      "Epoch 7/100\n",
      "223/223 [==============================] - 5337s 24s/step - loss: 0.0263 - accuracy: 0.2482 - val_loss: 0.0242 - val_accuracy: 0.2500\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16561183"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlyStopping = EarlyStopping( monitor='val_loss', min_delta=1.0e-4, patience=5, verbose=2, mode='auto' )\n",
    "callbacks = [earlyStopping]\n",
    "history = model.fit(new_train_X, new_train_y, batch_size=4, epochs=100, verbose=True, validation_split=0.1, callbacks=callbacks, shuffle=False)\n",
    "loss, accuracy  = model.evaluate(test_X, test_y, verbose=False)\n",
    "model.predict( test_X ).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1468,
     "status": "ok",
     "timestamp": 1611695029714,
     "user": {
      "displayName": "Jay Wang",
      "photoUrl": "",
      "userId": "08806282010227278078"
     },
     "user_tz": -780
    },
    "id": "PrLEmVp-8Fo3",
    "outputId": "daadccb5-ae14-4151-aefb-ce53725a4348"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.16561183], dtype=float32), 0.0)\n",
      "(array([0.16546367], dtype=float32), 0.0)\n",
      "(array([0.16529188], dtype=float32), 0.0)\n",
      "(array([0.16522959], dtype=float32), 0.0)\n",
      "(array([0.16526054], dtype=float32), 0.0)\n",
      "(array([0.16527964], dtype=float32), 0.0)\n",
      "(array([0.16528574], dtype=float32), 0.0)\n",
      "(array([0.16532879], dtype=float32), 0.0)\n",
      "(array([0.16536653], dtype=float32), 0.0)\n",
      "(array([0.16532221], dtype=float32), 0.0)\n",
      "(array([0.16527544], dtype=float32), 0.05)\n",
      "(array([0.1652001], dtype=float32), 0.25)\n",
      "(array([0.16511247], dtype=float32), 0.4)\n",
      "(array([0.16503191], dtype=float32), 0.25)\n",
      "(array([0.16499515], dtype=float32), 0.05)\n",
      "(array([0.16271263], dtype=float32), 0.0)\n",
      "(array([0.16269714], dtype=float32), 0.0)\n",
      "(array([0.16268533], dtype=float32), 0.0)\n",
      "(array([0.16267209], dtype=float32), 0.0)\n",
      "(array([0.16266593], dtype=float32), 0.0)\n",
      "(array([0.1626696], dtype=float32), 0.0)\n",
      "(array([0.16268998], dtype=float32), 0.0)\n",
      "(array([0.16272126], dtype=float32), 0.0)\n",
      "(array([0.16276258], dtype=float32), 0.0)\n",
      "(array([0.16281861], dtype=float32), 0.0)\n",
      "(array([0.16287361], dtype=float32), 0.05)\n",
      "(array([0.16291232], dtype=float32), 0.25)\n",
      "(array([0.16293384], dtype=float32), 0.4)\n",
      "(array([0.16294435], dtype=float32), 0.25)\n",
      "(array([0.16294873], dtype=float32), 0.05)\n",
      "(array([0.16337568], dtype=float32), 0.0)\n",
      "(array([0.16345298], dtype=float32), 0.0)\n",
      "(array([0.1635241], dtype=float32), 0.0)\n",
      "(array([0.16359296], dtype=float32), 0.0)\n",
      "(array([0.16365919], dtype=float32), 0.0)\n",
      "(array([0.16372204], dtype=float32), 0.0)\n",
      "(array([0.1637812], dtype=float32), 0.0)\n",
      "(array([0.16384181], dtype=float32), 0.0)\n",
      "(array([0.16390094], dtype=float32), 0.0)\n",
      "(array([0.16395932], dtype=float32), 0.0)\n",
      "(array([0.16402023], dtype=float32), 0.05)\n",
      "(array([0.16408113], dtype=float32), 0.25)\n",
      "(array([0.16414064], dtype=float32), 0.4)\n",
      "(array([0.16419633], dtype=float32), 0.25)\n",
      "(array([0.16425273], dtype=float32), 0.05)\n"
     ]
    }
   ],
   "source": [
    "a = zip(model.predict( test_X ), test_y)\n",
    "for i in a:\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "executionInfo": {
     "elapsed": 600,
     "status": "error",
     "timestamp": 1611702366414,
     "user": {
      "displayName": "Jay Wang",
      "photoUrl": "",
      "userId": "08806282010227278078"
     },
     "user_tz": -780
    },
    "id": "eZQfiL5kopT9",
    "outputId": "c170d833-dffb-4118-96c9-f2e1b6b7842b"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_loss_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-24d0a8957146>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_loss_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test loss: {loss:.3}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test accuracy: {accuracy:.3}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_loss_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "plot_loss_accuracy(history)\n",
    "print(f'Test loss: {loss:.3}')\n",
    "print(f'Test accuracy: {accuracy:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 803,
     "status": "ok",
     "timestamp": 1611658874392,
     "user": {
      "displayName": "Jay Wang",
      "photoUrl": "",
      "userId": "08806282010227278078"
     },
     "user_tz": -780
    },
    "id": "vNE058TLT6x6",
    "outputId": "0718e3a8-db48-49b8-97d9-56680dbbfbaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.6714285612106323,\n",
       "  0.6714285612106323,\n",
       "  0.6714285612106323,\n",
       "  0.6714285612106323,\n",
       "  0.6714285612106323,\n",
       "  0.6714285612106323],\n",
       " 'loss': [0.015060091391205788,\n",
       "  0.015102903358638287,\n",
       "  0.015099053271114826,\n",
       "  0.0150075051933527,\n",
       "  0.015055696479976177,\n",
       "  0.015163478441536427],\n",
       " 'val_accuracy': [0.6666666865348816,\n",
       "  0.6666666865348816,\n",
       "  0.6666666865348816,\n",
       "  0.6666666865348816,\n",
       "  0.6666666865348816,\n",
       "  0.6666666865348816],\n",
       " 'val_loss': [0.014888928271830082,\n",
       "  0.01488894410431385,\n",
       "  0.014889311045408249,\n",
       "  0.014888972043991089,\n",
       "  0.014888884499669075,\n",
       "  0.014889095909893513]}"
      ]
     },
     "execution_count": 153,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 830,
     "status": "ok",
     "timestamp": 1611704690258,
     "user": {
      "displayName": "Jay Wang",
      "photoUrl": "",
      "userId": "08806282010227278078"
     },
     "user_tz": -780
    },
    "id": "UagwVAbngYyi"
   },
   "outputs": [],
   "source": [
    "def modelFit():\n",
    "  earlyStopping = EarlyStopping( monitor='val_loss', min_delta=1.0e-4, patience=5, verbose=2, mode='auto' )\n",
    "  callbacks = [earlyStopping]\n",
    "  history = model.fit(train_X, train_y, batch_size=4, epochs=100, verbose=True, validation_data=( test_X, test_y ), callbacks=callbacks, shuffle=False)\n",
    "  loss, accuracy  = model.evaluate(test_X, test_y, verbose=False)\n",
    "  return model.predict( test_X ).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 623,
     "status": "ok",
     "timestamp": 1611704691426,
     "user": {
      "displayName": "Jay Wang",
      "photoUrl": "",
      "userId": "08806282010227278078"
     },
     "user_tz": -780
    },
    "id": "cVAz2QygKimZ"
   },
   "outputs": [],
   "source": [
    "def modeltests( **kwargs ):\n",
    "#  return math.sqrt( kwargs['layers']) *math.sin( kwargs['neurons'])\n",
    "  model = build_convnet( **kwargs )\n",
    "  if model:\n",
    "    result = modelFit()\n",
    "    return float(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08WwxaHtgCE2",
    "outputId": "fc05360c-e327-4d01-91a6-227a9fac2c8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |  kernels  |  layers   |  neurons  |  shrink   |\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 1/100\n",
      "57/57 [==============================] - 212s 4s/step - loss: 0.0179 - accuracy: 0.6835 - val_loss: 0.0151 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 201s 4s/step - loss: 0.0162 - accuracy: 0.6835 - val_loss: 0.0151 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 202s 4s/step - loss: 0.0162 - accuracy: 0.6835 - val_loss: 0.0151 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 204s 4s/step - loss: 0.0162 - accuracy: 0.6835 - val_loss: 0.0151 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 204s 4s/step - loss: 0.0162 - accuracy: 0.6835 - val_loss: 0.0151 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 203s 4s/step - loss: 0.0162 - accuracy: 0.6835 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 00006: early stopping\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.054   \u001b[0m | \u001b[0m 2.498   \u001b[0m | \u001b[0m 3.803   \u001b[0m | \u001b[0m 36.87   \u001b[0m | \u001b[0m 2.197   \u001b[0m |\n",
      "Epoch 1/100\n",
      "57/57 [==============================] - 204s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 208s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 210s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 211s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 211s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 212s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 00006: early stopping\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.05415 \u001b[0m | \u001b[95m 1.624   \u001b[0m | \u001b[95m 0.624   \u001b[0m | \u001b[95m 3.846   \u001b[0m | \u001b[95m 2.732   \u001b[0m |\n",
      "Epoch 1/100\n",
      "57/57 [==============================] - 213s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 222s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0151 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 216s 4s/step - loss: 0.0151 - accuracy: 0.6711 - val_loss: 0.0151 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 215s 4s/step - loss: 0.0151 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 214s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 215s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 00006: early stopping\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.05431 \u001b[0m | \u001b[95m 3.404   \u001b[0m | \u001b[95m 2.832   \u001b[0m | \u001b[95m 2.009   \u001b[0m | \u001b[95m 2.94    \u001b[0m |\n",
      "Epoch 1/100\n",
      "57/57 [==============================] - 216s 4s/step - loss: 0.0151 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 215s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 215s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 215s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 214s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 215s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 00006: early stopping\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.05449 \u001b[0m | \u001b[95m 4.33    \u001b[0m | \u001b[95m 0.8494  \u001b[0m | \u001b[95m 9.909   \u001b[0m | \u001b[95m 1.367   \u001b[0m |\n",
      "Epoch 1/100\n",
      "57/57 [==============================] - 214s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 215s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 214s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 215s 4s/step - loss: 0.0151 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 214s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 213s 4s/step - loss: 0.0151 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 00006: early stopping\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.05437 \u001b[0m | \u001b[0m 2.217   \u001b[0m | \u001b[0m 2.099   \u001b[0m | \u001b[0m 22.17   \u001b[0m | \u001b[0m 1.582   \u001b[0m |\n",
      "Epoch 1/100\n",
      "57/57 [==============================] - 213s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 213s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 214s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 213s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 214s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 213s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 00006: early stopping\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.05441 \u001b[0m | \u001b[0m 3.447   \u001b[0m | \u001b[0m 0.558   \u001b[0m | \u001b[0m 15.32   \u001b[0m | \u001b[0m 1.733   \u001b[0m |\n",
      "Epoch 1/100\n",
      "57/57 [==============================] - 213s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 213s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 213s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 213s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 212s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 212s 4s/step - loss: 0.0151 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 00006: early stopping\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.05448 \u001b[0m | \u001b[0m 2.824   \u001b[0m | \u001b[0m 3.141   \u001b[0m | \u001b[0m 10.78   \u001b[0m | \u001b[0m 2.028   \u001b[0m |\n",
      "Epoch 1/100\n",
      "57/57 [==============================] - 212s 4s/step - loss: 0.0151 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 212s 4s/step - loss: 0.0151 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 212s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 212s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 212s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 212s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 00006: early stopping\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m 0.05481 \u001b[0m | \u001b[95m 3.37    \u001b[0m | \u001b[95m 0.1858  \u001b[0m | \u001b[95m 30.77   \u001b[0m | \u001b[95m 1.341   \u001b[0m |\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 211s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 211s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 212s 4s/step - loss: 0.0151 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 211s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 212s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 211s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 00006: early stopping\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m 0.05492 \u001b[0m | \u001b[95m 1.26    \u001b[0m | \u001b[95m 3.796   \u001b[0m | \u001b[95m 48.32   \u001b[0m | \u001b[95m 2.617   \u001b[0m |\n",
      "Epoch 1/100\n",
      "57/57 [==============================] - 211s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 211s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 211s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 211s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 211s 4s/step - loss: 0.0151 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 211s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 00006: early stopping\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.05482 \u001b[0m | \u001b[0m 2.218   \u001b[0m | \u001b[0m 0.3907  \u001b[0m | \u001b[0m 34.53   \u001b[0m | \u001b[0m 1.88    \u001b[0m |\n",
      "Epoch 1/100\n",
      "57/57 [==============================] - 210s 4s/step - loss: 0.0151 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 209s 4s/step - loss: 0.0151 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 209s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 209s 4s/step - loss: 0.0151 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 209s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 209s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 00006: early stopping\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.05474 \u001b[0m | \u001b[0m 1.488   \u001b[0m | \u001b[0m 1.981   \u001b[0m | \u001b[0m 2.685   \u001b[0m | \u001b[0m 2.819   \u001b[0m |\n",
      "Epoch 1/100\n",
      "57/57 [==============================] - 209s 4s/step - loss: 0.0151 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 209s 4s/step - loss: 0.0151 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 209s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 208s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 209s 4s/step - loss: 0.0151 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 208s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 00006: early stopping\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.05484 \u001b[0m | \u001b[0m 2.035   \u001b[0m | \u001b[0m 2.65    \u001b[0m | \u001b[0m 16.27   \u001b[0m | \u001b[0m 2.04    \u001b[0m |\n",
      "Epoch 1/100\n",
      "57/57 [==============================] - 208s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 207s 4s/step - loss: 0.0151 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 207s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 207s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 207s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 207s 4s/step - loss: 0.0151 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 00006: early stopping\n",
      "| \u001b[95m 13      \u001b[0m | \u001b[95m 0.05498 \u001b[0m | \u001b[95m 2.453   \u001b[0m | \u001b[95m 0.2091  \u001b[0m | \u001b[95m 34.59   \u001b[0m | \u001b[95m 1.872   \u001b[0m |\n",
      "Epoch 1/100\n",
      "57/57 [==============================] - 207s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 207s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 208s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 206s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 207s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 206s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 00006: early stopping\n",
      "| \u001b[95m 14      \u001b[0m | \u001b[95m 0.05506 \u001b[0m | \u001b[95m 2.942   \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 34.44   \u001b[0m | \u001b[95m 2.245   \u001b[0m |\n",
      "Epoch 1/100\n",
      "57/57 [==============================] - 206s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 206s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 206s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 205s 4s/step - loss: 0.0151 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 205s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 205s 4s/step - loss: 0.0151 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 00006: early stopping\n",
      "| \u001b[95m 15      \u001b[0m | \u001b[95m 0.05526 \u001b[0m | \u001b[95m 3.573   \u001b[0m | \u001b[95m 0.1856  \u001b[0m | \u001b[95m 35.23   \u001b[0m | \u001b[95m 1.639   \u001b[0m |\n",
      "Epoch 1/100\n",
      "57/57 [==============================] - 206s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 205s 4s/step - loss: 0.0151 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 205s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 205s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 204s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 204s 4s/step - loss: 0.0151 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 00006: early stopping\n",
      "| \u001b[95m 16      \u001b[0m | \u001b[95m 0.05534 \u001b[0m | \u001b[95m 3.672   \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 34.32   \u001b[0m | \u001b[95m 1.0     \u001b[0m |\n",
      "Epoch 1/100\n",
      "57/57 [==============================] - 204s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 204s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 204s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 204s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 204s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 204s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 00006: early stopping\n",
      "| \u001b[95m 17      \u001b[0m | \u001b[95m 0.05536 \u001b[0m | \u001b[95m 4.987   \u001b[0m | \u001b[95m 0.0214  \u001b[0m | \u001b[95m 34.07   \u001b[0m | \u001b[95m 1.956   \u001b[0m |\n",
      "Epoch 1/100\n",
      "57/57 [==============================] - 204s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 205s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 203s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 204s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 203s 4s/step - loss: 0.0151 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 203s 4s/step - loss: 0.0151 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 00006: early stopping\n",
      "| \u001b[95m 18      \u001b[0m | \u001b[95m 0.05537 \u001b[0m | \u001b[95m 4.646   \u001b[0m | \u001b[95m 1.431   \u001b[0m | \u001b[95m 34.25   \u001b[0m | \u001b[95m 1.038   \u001b[0m |\n",
      "Epoch 1/100\n",
      "57/57 [==============================] - 204s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 203s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 203s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 203s 4s/step - loss: 0.0151 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 204s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 204s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 00006: early stopping\n",
      "| \u001b[95m 19      \u001b[0m | \u001b[95m 0.05561 \u001b[0m | \u001b[95m 5.0     \u001b[0m | \u001b[95m 0.9348  \u001b[0m | \u001b[95m 32.69   \u001b[0m | \u001b[95m 1.0     \u001b[0m |\n",
      "Epoch 1/100\n",
      "57/57 [==============================] - 204s 4s/step - loss: 0.0151 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "57/57 [==============================] - 204s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "57/57 [==============================] - 204s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "57/57 [==============================] - 204s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "57/57 [==============================] - 203s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "57/57 [==============================] - 203s 4s/step - loss: 0.0150 - accuracy: 0.6711 - val_loss: 0.0150 - val_accuracy: 0.6667\n",
      "Epoch 00006: early stopping\n",
      "| \u001b[95m 20      \u001b[0m | \u001b[95m 0.05565 \u001b[0m | \u001b[95m 4.943   \u001b[0m | \u001b[95m 2.558   \u001b[0m | \u001b[95m 32.3    \u001b[0m | \u001b[95m 1.955   \u001b[0m |\n",
      "=========================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'target': 0.055646516382694244,\n",
       " 'params': {'kernels': 4.942993803924221,\n",
       "  'layers': 2.55841474322518,\n",
       "  'neurons': 32.29901153587193,\n",
       "  'shrink': 1.9550955943743022}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pbounds = { 'layers': ( 0, 4 ), # number of \"return_sequences=True\" ConvLSTM layers\n",
    "            'neurons': ( 1, 50 ), # all layers have this number of neurons (at present)\n",
    "            'kernels': ( 1, 5 ), # int( kernel ) *2 +1 - odd numbers 3, 5, 7, 9, &c.\n",
    "            'shrink': (1, 3)\n",
    "          }\n",
    "optimizer = BayesianOptimization(\n",
    "                            f=modeltests,\n",
    "                            pbounds=pbounds,\n",
    "                            verbose=10,\n",
    "                            random_state=42\n",
    "                            )\n",
    "optimizer.maximize( init_points=12, n_iter=8 )\n",
    "optimizer.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z-UihN_Y3731"
   },
   "outputs": [],
   "source": [
    "def printModel( model, filename ):\n",
    "    try:\n",
    "        print( model.summary())\n",
    "            plot_model( model, to_file=filename, show_shapes=True )\n",
    "    except ValueError as ex:\n",
    "        print( '\\nUnable to print model summary:{}\\n'.format( ex ))\n",
    "        return\n",
    "    except ImportError as ex:\n",
    "        print( '\\nUnable  to print model:{}\\n'.format( ex ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1324,
     "status": "ok",
     "timestamp": 1611699405716,
     "user": {
      "displayName": "Jay Wang",
      "photoUrl": "",
      "userId": "08806282010227278078"
     },
     "user_tz": -780
    },
    "id": "tEfqJf4yvjD1",
    "outputId": "f451ba9c-88b1-4c61-b656-bbe7e78b2d24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "base (ConvLSTM2D)            (None, 10, 50, 50, 32)    363008    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_30 (MaxPooling (None, 10, 25, 25, 32)    0         \n",
      "_________________________________________________________________\n",
      "myThing0 (ConvLSTM2D)        (None, 10, 25, 25, 2)     22040     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_31 (MaxPooling (None, 10, 12, 12, 2)     0         \n",
      "_________________________________________________________________\n",
      "myThing1 (ConvLSTM2D)        (None, 10, 12, 12, 2)     2600      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_32 (MaxPooling (None, 10, 6, 6, 2)       0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_43 (ConvLSTM2D) (None, 6, 6, 2)           2600      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 6, 3, 2)           0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 6, 3, 320)         960       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 6, 3, 320)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 6, 3, 320)         0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 6, 3, 1)           321       \n",
      "=================================================================\n",
      "Total params: 391,529\n",
      "Trainable params: 391,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "printModel(model, 'fred.png')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMP14TuA3zuMJOEM6YDhRpc",
   "collapsed_sections": [],
   "name": "TECAnomaly.ipynb",
   "provenance": [
    {
     "file_id": "10L-pPvhnX68gN81heSp8AUqXlWpCyWbE",
     "timestamp": 1611030999427
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
